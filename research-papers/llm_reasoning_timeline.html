<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Evolution of LLM Reasoning - A Metro Map</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #0a0a0a;
            --bg-card: #111111;
            --bg-card-hover: #1a1a1a;
            --bg-expanded: #0d0d0d;
            --border: #222222;
            --text: #ffffff;
            --text-secondary: #999999;
            --text-muted: #666666;

            /* Metro Line Colors */
            --line-cot: #DC8850;
            --line-action: #4CAF50;
            --line-tree: #2196F3;
            --line-program: #9C27B0;
            --line-survey: #E91E63;

            --font-sans: 'Inter', -apple-system, sans-serif;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-sans);
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            -webkit-font-smoothing: antialiased;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        /* Header */
        .header {
            text-align: center;
            margin-bottom: 60px;
        }

        .header h1 {
            font-size: clamp(32px, 5vw, 56px);
            font-weight: 800;
            letter-spacing: -0.03em;
            margin-bottom: 16px;
            background: linear-gradient(135deg, #fff 0%, #999 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .header .subtitle {
            font-size: 20px;
            color: var(--text-secondary);
            max-width: 600px;
            margin: 0 auto 24px;
        }

        .header .meta {
            font-size: 14px;
            color: var(--text-muted);
        }

        /* Legend */
        .legend {
            display: flex;
            justify-content: center;
            gap: 24px;
            flex-wrap: wrap;
            margin-bottom: 48px;
            padding: 20px;
            background: var(--bg-card);
            border-radius: 12px;
            border: 1px solid var(--border);
        }

        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
            font-weight: 500;
        }

        .legend-dot {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            border: 3px solid currentColor;
            background: var(--bg);
        }

        .legend-item.cot { color: var(--line-cot); }
        .legend-item.action { color: var(--line-action); }
        .legend-item.tree { color: var(--line-tree); }
        .legend-item.program { color: var(--line-program); }
        .legend-item.survey { color: var(--line-survey); }

        /* Metro Map Container */
        .metro-map {
            background: var(--bg-card);
            border-radius: 16px;
            border: 1px solid var(--border);
            padding: 40px;
            margin-bottom: 60px;
            overflow-x: auto;
        }

        .metro-svg {
            width: 100%;
            min-width: 900px;
            height: 500px;
        }

        /* SVG Styles */
        .metro-line {
            fill: none;
            stroke-width: 6;
            stroke-linecap: round;
        }

        .metro-line.cot { stroke: var(--line-cot); }
        .metro-line.action { stroke: var(--line-action); }
        .metro-line.tree { stroke: var(--line-tree); }
        .metro-line.program { stroke: var(--line-program); }

        .station {
            cursor: pointer;
        }

        /* Scale the circles, not the group - prevents hover jitter */
        .station-outer,
        .station-inner {
            transition: r 0.2s ease, stroke-width 0.2s ease;
        }

        .station:hover .station-outer {
            r: 18;
            stroke-width: 5;
        }

        .station:hover .station-inner {
            r: 9;
        }

        .station-outer {
            fill: var(--bg);
            stroke-width: 4;
        }

        .station-outer.cot { stroke: var(--line-cot); }
        .station-outer.action { stroke: var(--line-action); }
        .station-outer.tree { stroke: var(--line-tree); }
        .station-outer.program { stroke: var(--line-program); }

        .station-inner {
            fill: var(--bg);
        }

        .station-label {
            font-family: var(--font-sans);
            font-size: 11px;
            font-weight: 600;
            fill: var(--text);
        }

        .station-sublabel {
            font-family: var(--font-sans);
            font-size: 9px;
            fill: var(--text-muted);
        }

        .year-marker {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            fill: var(--text-muted);
        }

        .interchange {
            fill: var(--bg);
            stroke: #fff;
            stroke-width: 3;
        }

        /* Tooltip */
        .tooltip {
            position: fixed;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 16px;
            max-width: 320px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.5);
            z-index: 1000;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s ease;
        }

        .tooltip.visible {
            opacity: 1;
        }

        .tooltip-title {
            font-weight: 700;
            font-size: 14px;
            margin-bottom: 4px;
        }

        .tooltip-authors {
            font-size: 12px;
            color: var(--text-secondary);
            margin-bottom: 8px;
        }

        .tooltip-idea {
            font-size: 13px;
            line-height: 1.5;
            margin-bottom: 8px;
        }

        .tooltip-citations {
            font-size: 12px;
            color: var(--line-cot);
            font-weight: 600;
        }

        /* Section Headers */
        .section-header {
            display: flex;
            align-items: center;
            gap: 16px;
            margin-bottom: 32px;
        }

        .section-header h2 {
            font-size: 28px;
            font-weight: 700;
        }

        .section-header .line-indicator {
            width: 40px;
            height: 6px;
            border-radius: 3px;
        }

        .section-header .line-indicator.cot { background: var(--line-cot); }
        .section-header .line-indicator.action { background: var(--line-action); }
        .section-header .line-indicator.tree { background: var(--line-tree); }
        .section-header .line-indicator.program { background: var(--line-program); }
        .section-header .line-indicator.survey { background: var(--line-survey); }

        /* Paper Cards - Expandable */
        .papers-grid {
            display: flex;
            flex-direction: column;
            gap: 16px;
            margin-bottom: 60px;
        }

        .paper-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            overflow: hidden;
            transition: all 0.3s ease;
            position: relative;
        }

        .paper-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 4px;
            height: 100%;
        }

        .paper-card.cot::before { background: var(--line-cot); }
        .paper-card.action::before { background: var(--line-action); }
        .paper-card.tree::before { background: var(--line-tree); }
        .paper-card.program::before { background: var(--line-program); }
        .paper-card.survey::before { background: var(--line-survey); }

        .paper-card:hover {
            border-color: #333;
        }

        .paper-card.expanded {
            border-color: #444;
        }

        .paper-header {
            padding: 24px;
            padding-left: 28px;
            cursor: pointer;
            display: grid;
            grid-template-columns: 1fr auto;
            gap: 16px;
            align-items: start;
        }

        .paper-header:hover {
            background: var(--bg-card-hover);
        }

        .paper-header-content {
            flex: 1;
        }

        .paper-meta-badges {
            display: flex;
            gap: 8px;
            align-items: center;
            flex-wrap: wrap;
        }

        .station-badge {
            display: inline-block;
            padding: 4px 10px;
            border-radius: 20px;
            font-size: 11px;
            font-weight: 600;
        }

        .paper-card.cot .station-badge { background: rgba(220, 136, 80, 0.2); color: var(--line-cot); }
        .paper-card.action .station-badge { background: rgba(76, 175, 80, 0.2); color: var(--line-action); }
        .paper-card.tree .station-badge { background: rgba(33, 150, 243, 0.2); color: var(--line-tree); }
        .paper-card.program .station-badge { background: rgba(156, 39, 176, 0.2); color: var(--line-program); }
        .paper-card.survey .station-badge { background: rgba(233, 30, 99, 0.2); color: var(--line-survey); }

        .citation-badge {
            display: inline-flex;
            align-items: center;
            gap: 4px;
            padding: 4px 10px;
            border-radius: 20px;
            font-size: 11px;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.08);
            color: var(--text-secondary);
        }

        .citation-badge.high {
            background: rgba(220, 136, 80, 0.15);
            color: var(--line-cot);
        }

        .paper-card h3 {
            font-size: 17px;
            font-weight: 700;
            margin: 8px 0;
            line-height: 1.4;
            color: var(--text);
        }

        .paper-card .authors {
            font-size: 13px;
            color: var(--text-secondary);
            margin-bottom: 8px;
        }

        .paper-card .idea {
            font-size: 14px;
            color: var(--text-muted);
            line-height: 1.5;
        }

        .expand-icon {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            background: rgba(255,255,255,0.05);
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--text-muted);
            transition: all 0.3s ease;
            flex-shrink: 0;
        }

        .paper-card.expanded .expand-icon {
            transform: rotate(180deg);
            background: rgba(255,255,255,0.1);
        }

        /* Expanded Content */
        .paper-expanded {
            display: none;
            background: var(--bg-expanded);
            border-top: 1px solid var(--border);
            padding: 24px;
            padding-left: 28px;
        }

        .paper-card.expanded .paper-expanded {
            display: block;
        }

        .expanded-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 24px;
        }

        .expanded-section {
            background: var(--bg-card);
            border-radius: 8px;
            padding: 16px;
            border: 1px solid var(--border);
        }

        .expanded-section h4 {
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            color: var(--text-muted);
            margin-bottom: 12px;
        }

        .expanded-section ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .expanded-section li {
            font-size: 14px;
            color: var(--text-secondary);
            padding: 6px 0;
            border-bottom: 1px solid rgba(255,255,255,0.05);
            line-height: 1.5;
        }

        .expanded-section li:last-child {
            border-bottom: none;
        }

        .expanded-section li strong {
            color: var(--text);
        }

        .expanded-section p {
            font-size: 14px;
            color: var(--text-secondary);
            line-height: 1.6;
        }

        .metric-highlight {
            color: var(--line-cot);
            font-weight: 600;
        }

        .metric-green {
            color: var(--line-action);
            font-weight: 600;
        }

        /* Links Section */
        .paper-links {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 16px;
            padding-top: 16px;
            border-top: 1px solid var(--border);
        }

        .paper-link {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 14px;
            border-radius: 6px;
            font-size: 13px;
            font-weight: 500;
            text-decoration: none;
            transition: all 0.2s ease;
            background: rgba(255,255,255,0.05);
            color: var(--text-secondary);
            border: 1px solid transparent;
        }

        .paper-link:hover {
            background: rgba(255,255,255,0.1);
            color: var(--text);
            border-color: var(--border);
        }

        .paper-link.primary {
            background: rgba(220, 136, 80, 0.15);
            color: var(--line-cot);
        }

        .paper-link.primary:hover {
            background: rgba(220, 136, 80, 0.25);
        }

        .paper-link svg {
            width: 14px;
            height: 14px;
        }

        /* Insights Section */
        .insights-section {
            background: linear-gradient(135deg, rgba(220, 136, 80, 0.1) 0%, rgba(156, 39, 176, 0.1) 100%);
            border-radius: 16px;
            padding: 40px;
            margin-bottom: 60px;
            border: 1px solid var(--border);
        }

        .insights-section h2 {
            font-size: 24px;
            margin-bottom: 24px;
        }

        .insight-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
        }

        /* Frontier Section */
        .frontier-section {
            background: linear-gradient(135deg, rgba(33, 150, 243, 0.08) 0%, rgba(156, 39, 176, 0.08) 100%);
            border-radius: 20px;
            padding: 48px;
            margin-bottom: 60px;
            border: 1px solid var(--border);
        }

        .frontier-section h2 {
            font-size: 28px;
            margin-bottom: 12px;
        }

        .frontier-intro {
            color: var(--text-secondary);
            font-size: 16px;
            margin-bottom: 32px;
        }

        .frontier-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 24px;
            margin-bottom: 32px;
        }

        .frontier-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 16px;
            padding: 24px;
            transition: all 0.2s ease;
        }

        .frontier-card:hover {
            border-color: var(--line-tree);
            transform: translateY(-2px);
        }

        .frontier-icon {
            font-size: 28px;
            margin-bottom: 12px;
        }

        .frontier-card h4 {
            font-size: 17px;
            font-weight: 700;
            margin-bottom: 10px;
            color: var(--text);
        }

        .frontier-card p {
            font-size: 14px;
            color: var(--text-secondary);
            line-height: 1.6;
            margin-bottom: 16px;
        }

        .frontier-stat {
            background: rgba(33, 150, 243, 0.1);
            padding: 12px;
            border-radius: 8px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 12px;
        }

        .frontier-stat .stat-label {
            font-size: 12px;
            color: var(--text-muted);
        }

        .frontier-stat .stat-value {
            font-size: 14px;
            font-weight: 700;
            color: var(--line-tree);
        }

        .frontier-bottom-line {
            background: var(--bg-card);
            padding: 20px 24px;
            border-radius: 12px;
            font-size: 15px;
            color: var(--text-secondary);
            border-left: 4px solid var(--line-tree);
        }

        .frontier-bottom-line strong {
            color: var(--text);
        }

        .insight-card {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid var(--border);
        }

        .insight-card h4 {
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 8px;
            color: var(--line-cot);
        }

        .insight-card p {
            font-size: 14px;
            color: var(--text-secondary);
            line-height: 1.5;
        }

        /* Enhanced Content Styles */
        .example-prompt {
            background: #1a1510;
            border: 1px solid rgba(220, 136, 80, 0.3);
            border-radius: 8px;
            padding: 16px;
            margin: 12px 0;
            font-family: 'SF Mono', 'Monaco', 'Inconsolata', monospace;
            font-size: 13px;
            line-height: 1.6;
            color: #e8dcc8;
            overflow-x: auto;
            white-space: pre-wrap;
        }

        .example-prompt .prompt-label {
            color: var(--line-cot);
            font-weight: 600;
            display: block;
            margin-bottom: 8px;
            font-family: var(--font-sans);
            text-transform: uppercase;
            font-size: 11px;
            letter-spacing: 0.5px;
        }

        .code-block {
            background: #0d1117;
            border: 1px solid #30363d;
            border-radius: 8px;
            padding: 16px;
            margin: 12px 0;
            font-family: 'SF Mono', 'Monaco', 'Inconsolata', monospace;
            font-size: 13px;
            line-height: 1.5;
            color: #c9d1d9;
            overflow-x: auto;
        }

        .code-block .comment {
            color: #8b949e;
        }

        .code-block .keyword {
            color: #ff7b72;
        }

        .code-block .string {
            color: #a5d6ff;
        }

        .code-block .function {
            color: #d2a8ff;
        }

        .key-learning {
            background: linear-gradient(135deg, rgba(76, 175, 80, 0.1) 0%, rgba(76, 175, 80, 0.05) 100%);
            border: 1px solid rgba(76, 175, 80, 0.3);
            border-radius: 8px;
            padding: 16px;
            margin: 12px 0;
        }

        .key-learning h5 {
            color: var(--line-action);
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .key-learning p {
            color: var(--text-secondary);
            font-size: 14px;
            line-height: 1.6;
            margin: 0;
        }

        .technique-diagram {
            background: var(--bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px;
            margin: 12px 0;
            text-align: center;
            font-family: 'SF Mono', monospace;
            font-size: 12px;
            line-height: 2;
            color: var(--text-secondary);
            overflow-x: auto;
        }

        .technique-diagram .arrow {
            color: var(--line-cot);
        }

        .technique-diagram .node {
            display: inline-block;
            padding: 6px 12px;
            border-radius: 6px;
            background: rgba(255,255,255,0.05);
            border: 1px solid var(--border);
            margin: 4px;
        }

        .full-width-section {
            grid-column: 1 / -1;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 12px 0;
            font-size: 13px;
        }

        .comparison-table th,
        .comparison-table td {
            padding: 10px 12px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        .comparison-table th {
            color: var(--text-muted);
            font-weight: 600;
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .comparison-table td {
            color: var(--text-secondary);
        }

        .comparison-table tr:hover td {
            background: rgba(255,255,255,0.02);
        }

        .step-by-step {
            counter-reset: step;
        }

        .step-by-step .step {
            display: flex;
            gap: 12px;
            padding: 12px 0;
            border-bottom: 1px solid rgba(255,255,255,0.05);
        }

        .step-by-step .step:last-child {
            border-bottom: none;
        }

        .step-by-step .step-number {
            width: 28px;
            height: 28px;
            border-radius: 50%;
            background: rgba(220, 136, 80, 0.2);
            color: var(--line-cot);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 12px;
            font-weight: 700;
            flex-shrink: 0;
        }

        .step-by-step .step-content {
            flex: 1;
        }

        .step-by-step .step-title {
            font-weight: 600;
            color: var(--text);
            margin-bottom: 4px;
        }

        .step-by-step .step-desc {
            font-size: 13px;
            color: var(--text-secondary);
            line-height: 1.5;
        }

        .callout-box {
            background: rgba(33, 150, 243, 0.1);
            border: 1px solid rgba(33, 150, 243, 0.3);
            border-radius: 8px;
            padding: 14px;
            margin: 12px 0;
        }

        .callout-box.warning {
            background: rgba(255, 193, 7, 0.1);
            border-color: rgba(255, 193, 7, 0.3);
        }

        .callout-box h5 {
            color: var(--line-tree);
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 6px;
        }

        .callout-box.warning h5 {
            color: #ffc107;
        }

        .callout-box p {
            font-size: 13px;
            color: var(--text-secondary);
            margin: 0;
            line-height: 1.5;
        }

        /* Decision Framework */
        .decision-framework {
            background: linear-gradient(135deg, rgba(220, 136, 80, 0.05) 0%, rgba(33, 150, 243, 0.05) 100%);
            border: 2px solid var(--line-cot);
            border-radius: 20px;
            padding: 40px;
            margin-bottom: 60px;
        }

        .decision-framework h2 {
            font-size: 28px;
            margin-bottom: 12px;
            color: var(--text);
        }

        .decision-framework h3 {
            font-size: 20px;
            margin: 40px 0 20px 0;
            color: var(--text);
        }

        .framework-intro {
            font-size: 16px;
            color: var(--text-secondary);
            margin-bottom: 30px;
            line-height: 1.6;
        }

        .decision-tree {
            margin-bottom: 40px;
        }

        .decision-node {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 16px;
        }

        .decision-node.root {
            border: 2px solid var(--border);
        }

        .decision-node .question {
            font-weight: 600;
            color: var(--text);
            font-size: 16px;
            margin-bottom: 16px;
            text-align: center;
        }

        .decision-node .branches {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 16px;
        }

        .branch {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .branch-label {
            background: rgba(255, 255, 255, 0.05);
            padding: 8px 12px;
            border-radius: 6px;
            font-size: 13px;
            color: var(--text-muted);
            text-align: center;
            border: 1px solid var(--border);
        }

        .technique-box {
            padding: 16px;
            border-radius: 10px;
            border: 2px solid;
        }

        .technique-box.cot {
            background: rgba(220, 136, 80, 0.1);
            border-color: var(--line-cot);
        }

        .technique-box.action {
            background: rgba(76, 175, 80, 0.1);
            border-color: var(--line-action);
        }

        .technique-box.tree {
            background: rgba(33, 150, 243, 0.1);
            border-color: var(--line-tree);
        }

        .technique-box.program {
            background: rgba(156, 39, 176, 0.1);
            border-color: var(--line-program);
        }

        .technique-box strong {
            display: block;
            margin-bottom: 6px;
            font-size: 14px;
        }

        .technique-box p {
            font-size: 12px;
            color: var(--text-secondary);
            margin: 0;
            line-height: 1.4;
        }

        /* Decision Matrix */
        .matrix-container {
            overflow-x: auto;
        }

        .decision-matrix {
            width: 100%;
            border-collapse: collapse;
            font-size: 14px;
        }

        .decision-matrix th,
        .decision-matrix td {
            padding: 14px 16px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        .decision-matrix th {
            background: rgba(255, 255, 255, 0.02);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            color: var(--text-muted);
        }

        .decision-matrix td {
            color: var(--text-secondary);
        }

        .decision-matrix tr:hover td {
            background: rgba(255, 255, 255, 0.02);
        }

        .cot-row td:first-child { border-left: 3px solid var(--line-cot); }
        .action-row td:first-child { border-left: 3px solid var(--line-action); }
        .tree-row td:first-child { border-left: 3px solid var(--line-tree); }
        .program-row td:first-child { border-left: 3px solid var(--line-program); }

        /* Mistakes Grid */
        .mistakes-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 20px;
        }

        .mistake-card {
            background: var(--bg-card);
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid var(--border);
        }

        .mistake-header {
            background: rgba(255, 82, 82, 0.15);
            padding: 14px 18px;
            font-weight: 600;
            color: #ff5252;
            font-size: 14px;
        }

        .mistake-body {
            padding: 18px;
        }

        .mistake-body p {
            font-size: 13px;
            color: var(--text-secondary);
            line-height: 1.5;
            margin-bottom: 10px;
        }

        .mistake-body p:last-child {
            margin-bottom: 0;
        }

        .mistake-body strong {
            color: var(--text);
        }

        /* Production Tips */
        .production-tips {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 24px;
            border: 1px solid var(--border);
        }

        .tip-row {
            display: flex;
            gap: 20px;
            padding: 20px 0;
            border-bottom: 1px solid var(--border);
        }

        .tip-row:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .tip-row:first-child {
            padding-top: 0;
        }

        .tip-number {
            width: 36px;
            height: 36px;
            border-radius: 50%;
            background: var(--line-cot);
            color: #000;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 700;
            font-size: 16px;
            flex-shrink: 0;
        }

        .tip-content {
            flex: 1;
        }

        .tip-content strong {
            display: block;
            margin-bottom: 6px;
            color: var(--text);
            font-size: 15px;
        }

        .tip-content p {
            font-size: 13px;
            color: var(--text-secondary);
            margin: 0;
            line-height: 1.5;
        }

        /* Navigation */
        .nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 0;
            border-bottom: 1px solid var(--border);
            margin-bottom: 40px;
        }

        .nav a {
            color: var(--text-secondary);
            text-decoration: none;
            font-size: 14px;
            font-weight: 500;
            transition: color 0.2s;
        }

        .nav a:hover {
            color: var(--line-cot);
        }

        .nav-links {
            display: flex;
            gap: 24px;
        }

        /* Footer */
        .footer {
            text-align: center;
            padding: 40px 0;
            border-top: 1px solid var(--border);
            margin-top: 60px;
        }

        .footer p {
            color: var(--text-muted);
            font-size: 14px;
        }

        .footer a {
            color: var(--line-cot);
            text-decoration: none;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .legend {
                gap: 16px;
            }

            .metro-map {
                padding: 20px;
            }

            .nav-links {
                display: none;
            }

            .paper-header {
                grid-template-columns: 1fr;
            }

            .expand-icon {
                position: absolute;
                top: 24px;
                right: 24px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Navigation -->
        <nav class="nav">
            <a href="../index.html">‚Üê Home</a>
            <div class="nav-links">
                <a href="index.html">Research Papers</a>
                <a href="../agent/index.html">Agent Reliability</a>
                <a href="../rag/index.html">RAG Patterns</a>
                <a href="https://join.maxpool.dev" target="_blank">Join Community ‚Üí</a>
            </div>
        </nav>

        <!-- Header -->
        <header class="header">
            <h1>The Evolution of LLM Reasoning</h1>
            <p class="subtitle">A metro map of how language models learned to think step by step</p>
            <p class="meta">From Chain-of-Thought to Large Reasoning Models ‚Ä¢ 2022‚Äì2025</p>
        </header>

        <!-- Legend -->
        <div class="legend">
            <div class="legend-item cot">
                <div class="legend-dot"></div>
                Chain-of-Thought
            </div>
            <div class="legend-item action">
                <div class="legend-dot"></div>
                Action & Agents
            </div>
            <div class="legend-item tree">
                <div class="legend-dot"></div>
                Tree & Search
            </div>
            <div class="legend-item program">
                <div class="legend-dot"></div>
                Program-Based
            </div>
            <div class="legend-item survey">
                <div class="legend-dot"></div>
                Surveys & Meta
            </div>
        </div>

        <!-- Metro Map SVG -->
        <div class="metro-map">
            <svg class="metro-svg" viewBox="0 0 1100 400">
                <!-- Year markers -->
                <text x="100" y="25" class="year-marker">2022</text>
                <text x="400" y="25" class="year-marker">2023</text>
                <text x="700" y="25" class="year-marker">2024</text>
                <text x="1000" y="25" class="year-marker">2025</text>

                <!-- Vertical year lines -->
                <line x1="130" y1="40" x2="130" y2="360" stroke="#222" stroke-width="1" stroke-dasharray="4"/>
                <line x1="430" y1="40" x2="430" y2="360" stroke="#222" stroke-width="1" stroke-dasharray="4"/>
                <line x1="730" y1="40" x2="730" y2="360" stroke="#222" stroke-width="1" stroke-dasharray="4"/>

                <!-- TRACK LAYOUT - 4 clean parallel horizontal lines -->

                <!-- Chain-of-Thought Line (Orange) - y=80 -->
                <path class="metro-line cot" d="M 40 80 H 1060"/>

                <!-- Action Line (Green) - y=160 -->
                <path class="metro-line action" d="M 40 160 H 1060"/>

                <!-- Tree Line (Blue) - y=240 -->
                <path class="metro-line tree" d="M 40 240 H 1060"/>

                <!-- Program Line (Purple) - y=320 -->
                <path class="metro-line program" d="M 40 320 H 1060"/>

                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
                <!-- CHAIN-OF-THOUGHT STATIONS (Orange Line) -->
                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

                <g class="station" data-paper="cot">
                    <circle cx="100" cy="80" r="14" class="station-outer cot"/>
                    <circle cx="100" cy="80" r="6" class="station-inner"/>
                    <text x="100" y="60" class="station-label" text-anchor="middle">CoT</text>
                    <text x="100" y="48" class="station-sublabel" text-anchor="middle">17.7k cites</text>
                </g>

                <g class="station" data-paper="self-consistency">
                    <circle cx="200" cy="80" r="14" class="station-outer cot"/>
                    <circle cx="200" cy="80" r="6" class="station-inner"/>
                    <text x="200" y="110" class="station-label" text-anchor="middle">Self-Consistency</text>
                    <text x="200" y="122" class="station-sublabel" text-anchor="middle">4.2k cites</text>
                </g>

                <g class="station" data-paper="least-to-most">
                    <circle cx="300" cy="80" r="14" class="station-outer cot"/>
                    <circle cx="300" cy="80" r="6" class="station-inner"/>
                    <text x="300" y="60" class="station-label" text-anchor="middle">Least-to-Most</text>
                    <text x="300" y="48" class="station-sublabel" text-anchor="middle">1.4k cites</text>
                </g>

                <g class="station" data-paper="cot-no-prompt">
                    <circle cx="780" cy="80" r="14" class="station-outer cot"/>
                    <circle cx="780" cy="80" r="6" class="station-inner"/>
                    <text x="780" y="110" class="station-label" text-anchor="middle">CoT w/o Prompt</text>
                    <text x="780" y="122" class="station-sublabel" text-anchor="middle">168 cites</text>
                </g>

                <g class="station" data-paper="sys2-survey">
                    <circle cx="950" cy="80" r="14" class="station-outer cot"/>
                    <circle cx="950" cy="80" r="6" class="station-inner"/>
                    <text x="950" y="60" class="station-label" text-anchor="middle">Sys1‚ÜíSys2</text>
                    <text x="950" y="48" class="station-sublabel" text-anchor="middle">Survey '25</text>
                </g>

                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
                <!-- ACTION STATIONS (Green Line) -->
                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

                <g class="station" data-paper="react">
                    <circle cx="200" cy="160" r="14" class="station-outer action"/>
                    <circle cx="200" cy="160" r="6" class="station-inner"/>
                    <text x="200" y="190" class="station-label" text-anchor="middle">ReAct</text>
                    <text x="200" y="202" class="station-sublabel" text-anchor="middle">5.9k cites</text>
                </g>

                <g class="station" data-paper="reflexion">
                    <circle cx="480" cy="160" r="14" class="station-outer action"/>
                    <circle cx="480" cy="160" r="6" class="station-inner"/>
                    <text x="480" y="190" class="station-label" text-anchor="middle">Reflexion</text>
                    <text x="480" y="202" class="station-sublabel" text-anchor="middle">2.9k cites</text>
                </g>

                <g class="station" data-paper="lrm-survey">
                    <circle cx="950" cy="160" r="14" class="station-outer action"/>
                    <circle cx="950" cy="160" r="6" class="station-inner"/>
                    <text x="950" y="140" class="station-label" text-anchor="middle">LRM Survey</text>
                    <text x="950" y="128" class="station-sublabel" text-anchor="middle">2025</text>
                </g>

                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
                <!-- TREE STATIONS (Blue Line) - y=240 -->
                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

                <g class="station" data-paper="tot">
                    <circle cx="480" cy="240" r="14" class="station-outer tree"/>
                    <circle cx="480" cy="240" r="6" class="station-inner"/>
                    <text x="480" y="270" class="station-label" text-anchor="middle">Tree of Thoughts</text>
                    <text x="480" y="282" class="station-sublabel" text-anchor="middle">4.9k cites</text>
                </g>

                <g class="station" data-paper="llm-tot">
                    <circle cx="650" cy="240" r="14" class="station-outer tree"/>
                    <circle cx="650" cy="240" r="6" class="station-inner"/>
                    <text x="650" y="220" class="station-label" text-anchor="middle">LLM-ToT</text>
                    <text x="650" y="208" class="station-sublabel" text-anchor="middle">314 cites</text>
                </g>

                <g class="station" data-paper="efficient-survey">
                    <circle cx="950" cy="240" r="14" class="station-outer tree"/>
                    <circle cx="950" cy="240" r="6" class="station-inner"/>
                    <text x="950" y="270" class="station-label" text-anchor="middle">Efficient Survey</text>
                    <text x="950" y="282" class="station-sublabel" text-anchor="middle">2025</text>
                </g>

                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
                <!-- PROGRAM STATIONS (Purple Line) - y=320 -->
                <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

                <g class="station" data-paper="pot">
                    <circle cx="250" cy="320" r="14" class="station-outer program"/>
                    <circle cx="250" cy="320" r="6" class="station-inner"/>
                    <text x="250" y="350" class="station-label" text-anchor="middle">Program of Thoughts</text>
                    <text x="250" y="362" class="station-sublabel" text-anchor="middle">1.1k cites</text>
                </g>

                <!-- Terminal arrows -->
                <polygon points="1060,80 1050,75 1050,85" fill="var(--line-cot)"/>
                <polygon points="1060,160 1050,155 1050,165" fill="var(--line-action)"/>
                <polygon points="1060,240 1050,235 1050,245" fill="var(--line-tree)"/>
                <polygon points="1060,320 1050,315 1050,325" fill="var(--line-program)"/>

            </svg>
        </div>

        <!-- The Frontier: What's Next for LLM Reasoning -->
        <div class="frontier-section">
            <h2>üöÄ The Frontier: What's Next</h2>
            <p class="frontier-intro">The reasoning landscape is evolving rapidly. Here are the key trends shaping 2025 and beyond.</p>

            <div class="frontier-grid">
                <div class="frontier-card">
                    <div class="frontier-icon">‚ö°</div>
                    <h4>Test-Time Compute Scaling</h4>
                    <p>The new scaling law: more thinking tokens = better results. o1/o3 and R1 prove you can trade inference cost for capability. The frontier is now <em>efficiency</em>‚Äîgetting the same gains with fewer tokens.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">o1 vs Gemini on same task:</span>
                        <span class="stat-value">138K vs 96 tokens</span>
                    </div>
                </div>

                <div class="frontier-card">
                    <div class="frontier-icon">üîÑ</div>
                    <h4>Verify-then-Generate</h4>
                    <p>The winning pattern: generate candidates, verify with a separate model/tool, iterate. External verifiers (code execution, formal proofs, unit tests) unlock gains <em>independent</em> of base model quality.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">Reflexion on HumanEval:</span>
                        <span class="stat-value">+24% with self-verification</span>
                    </div>
                </div>

                <div class="frontier-card">
                    <div class="frontier-icon">üß¨</div>
                    <h4>Reasoning Distillation</h4>
                    <p>Large reasoning models (o1, R1) generate training data for smaller models. DeepSeek-R1-Distill-Qwen-7B matches GPT-4o on math. The moat isn't the model‚Äîit's the reasoning traces.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">7B distilled vs 70B base:</span>
                        <span class="stat-value">Often comparable</span>
                    </div>
                </div>

                <div class="frontier-card">
                    <div class="frontier-icon">üéØ</div>
                    <h4>Adaptive Compute</h4>
                    <p>Not all problems need the same thinking budget. The next frontier: models that <em>know</em> when to think longer. Easy questions get fast answers; hard ones get extended reasoning.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">Goal:</span>
                        <span class="stat-value">Right-size thinking per query</span>
                    </div>
                </div>

                <div class="frontier-card">
                    <div class="frontier-icon">üîó</div>
                    <h4>Tool-Augmented Reasoning</h4>
                    <p>Pure language reasoning hits limits. The winners combine LLM reasoning with code execution (PoT), search (ReAct), and formal verification. Hybrid systems dominate benchmarks.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">PoT vs CoT on GSM8K:</span>
                        <span class="stat-value">+22% with code execution</span>
                    </div>
                </div>

                <div class="frontier-card">
                    <div class="frontier-icon">üìâ</div>
                    <h4>The Efficiency Crisis</h4>
                    <p>"Slow thinking" generates massive token counts. Research explores: compressed CoT (say less), distillation (smaller models), speculative decoding (faster generation). Cost per reasoning step must drop 10-100x.</p>
                    <div class="frontier-stat">
                        <span class="stat-label">Current challenge:</span>
                        <span class="stat-value">$0.10+ per complex query</span>
                    </div>
                </div>
            </div>

            <div class="frontier-bottom-line">
                <strong>The Bottom Line:</strong> We've proven LLMs can reason. The 2025 frontier is making that reasoning <em>efficient</em>, <em>reliable</em>, and <em>verifiable</em>. The techniques on this page are the building blocks.
            </div>
        </div>

        <!-- DECISION FRAMEWORK - The Most Valuable Section -->
        <div class="decision-framework">
            <h2>üéØ The Decision Framework: Which Technique Should You Use?</h2>
            <p class="framework-intro">Don't just learn these techniques‚Äîknow <em>when</em> to use each one. This decision tree distills 10 papers into actionable guidance.</p>

            <div class="decision-tree">
                <div class="decision-node root">
                    <div class="question">What type of problem are you solving?</div>
                    <div class="branches">
                        <div class="branch">
                            <div class="branch-label">Math/Computation</div>
                            <div class="decision-node">
                                <div class="question">Does it require calculation?</div>
                                <div class="branches">
                                    <div class="branch">
                                        <div class="branch-label">Yes</div>
                                        <div class="technique-box program">
                                            <strong>‚Üí Program of Thoughts</strong>
                                            <p>Let Python do the math. +22% on GSM8K.</p>
                                        </div>
                                    </div>
                                    <div class="branch">
                                        <div class="branch-label">No, just reasoning</div>
                                        <div class="technique-box cot">
                                            <strong>‚Üí Chain-of-Thought</strong>
                                            <p>Step-by-step natural language reasoning.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="branch">
                            <div class="branch-label">Needs External Info</div>
                            <div class="decision-node">
                                <div class="question">Can model hallucinate facts?</div>
                                <div class="branches">
                                    <div class="branch">
                                        <div class="branch-label">No, need real data</div>
                                        <div class="technique-box action">
                                            <strong>‚Üí ReAct</strong>
                                            <p>Interleave reasoning with tool calls.</p>
                                        </div>
                                    </div>
                                    <div class="branch">
                                        <div class="branch-label">Can self-correct</div>
                                        <div class="technique-box action">
                                            <strong>‚Üí Reflexion</strong>
                                            <p>Try, fail, reflect, retry. +24% on HumanEval.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="branch">
                            <div class="branch-label">Puzzles/Planning</div>
                            <div class="decision-node">
                                <div class="question">Might first approach be wrong?</div>
                                <div class="branches">
                                    <div class="branch">
                                        <div class="branch-label">Yes, need backtracking</div>
                                        <div class="technique-box tree">
                                            <strong>‚Üí Tree of Thoughts</strong>
                                            <p>Explore multiple paths. 4% ‚Üí 74% on Game of 24.</p>
                                        </div>
                                    </div>
                                    <div class="branch">
                                        <div class="branch-label">No, path is clear</div>
                                        <div class="technique-box cot">
                                            <strong>‚Üí Chain-of-Thought</strong>
                                            <p>Single path reasoning is enough.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="branch">
                            <div class="branch-label">Complex/Compositional</div>
                            <div class="technique-box cot">
                                <strong>‚Üí Least-to-Most</strong>
                                <p>Decompose, solve easy‚Üíhard. 99.7% on SCAN.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <h3>‚ö° The Quick Reference Matrix</h3>
            <div class="matrix-container">
                <table class="decision-matrix">
                    <thead>
                        <tr>
                            <th>Technique</th>
                            <th>Best For</th>
                            <th>Cost</th>
                            <th>Key Gain</th>
                            <th>Don't Use When</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="cot-row">
                            <td><strong>CoT</strong></td>
                            <td>Multi-step reasoning</td>
                            <td>1x</td>
                            <td>+40% GSM8K</td>
                            <td>Simple lookups, pattern matching</td>
                        </tr>
                        <tr class="cot-row">
                            <td><strong>Self-Consistency</strong></td>
                            <td>High-stakes accuracy</td>
                            <td>10-40x</td>
                            <td>+16% over CoT</td>
                            <td>Budget-constrained, latency-critical</td>
                        </tr>
                        <tr class="cot-row">
                            <td><strong>Least-to-Most</strong></td>
                            <td>Compositional tasks</td>
                            <td>2-5x</td>
                            <td>+84% SCAN</td>
                            <td>Non-decomposable problems</td>
                        </tr>
                        <tr class="action-row">
                            <td><strong>ReAct</strong></td>
                            <td>Tool use, grounding</td>
                            <td>3-10x</td>
                            <td>+10% FEVER</td>
                            <td>Closed-book reasoning</td>
                        </tr>
                        <tr class="action-row">
                            <td><strong>Reflexion</strong></td>
                            <td>Iterative improvement</td>
                            <td>2-5x</td>
                            <td>+24% HumanEval</td>
                            <td>No feedback signal available</td>
                        </tr>
                        <tr class="tree-row">
                            <td><strong>Tree of Thoughts</strong></td>
                            <td>Search/exploration</td>
                            <td>10-100x</td>
                            <td>+70% Game24</td>
                            <td>Simple problems, cost matters</td>
                        </tr>
                        <tr class="program-row">
                            <td><strong>Program of Thoughts</strong></td>
                            <td>Math-heavy tasks</td>
                            <td>1x + exec</td>
                            <td>+22% GSM8K</td>
                            <td>Non-computational reasoning</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>üö® The Mistakes Everyone Makes</h3>
            <div class="mistakes-grid">
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå Using CoT for everything</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Applying "think step by step" to simple factual questions.</p>
                        <p><strong>Why it's wrong:</strong> CoT adds latency and can confabulate reasoning for simple lookups. "What's the capital of France?" doesn't need step-by-step.</p>
                        <p><strong>Fix:</strong> Classify queries first. Use CoT only for multi-step reasoning.</p>
                    </div>
                </div>
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå ToT on simple problems</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Using Tree of Thoughts for problems where CoT suffices.</p>
                        <p><strong>Why it's wrong:</strong> ToT is 10-100x more expensive. If CoT works, you're burning money.</p>
                        <p><strong>Fix:</strong> Try CoT first. Only use ToT when CoT consistently fails.</p>
                    </div>
                </div>
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå Reflexion without feedback</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Trying to use Reflexion without a way to evaluate attempts.</p>
                        <p><strong>Why it's wrong:</strong> Reflexion needs signal. No feedback = no learning = just burning tokens.</p>
                        <p><strong>Fix:</strong> Ensure you have tests, verifiers, or ground truth before using Reflexion.</p>
                    </div>
                </div>
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå Self-Consistency with temp=0</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Running Self-Consistency with greedy decoding.</p>
                        <p><strong>Why it's wrong:</strong> Temperature=0 produces identical outputs. You're just generating the same answer N times.</p>
                        <p><strong>Fix:</strong> Use temperature 0.5-0.7 for diversity.</p>
                    </div>
                </div>
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå PoT for non-computational tasks</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Generating code for commonsense reasoning questions.</p>
                        <p><strong>Why it's wrong:</strong> "Is a penguin a bird?" doesn't benefit from Python. The model will generate silly code.</p>
                        <p><strong>Fix:</strong> Only use PoT when there's actual computation to offload.</p>
                    </div>
                </div>
                <div class="mistake-card">
                    <div class="mistake-header">‚ùå No max_steps in ReAct</div>
                    <div class="mistake-body">
                        <p><strong>The mistake:</strong> Running ReAct agents without step limits.</p>
                        <p><strong>Why it's wrong:</strong> Agents can loop forever, searching repeatedly without finishing.</p>
                        <p><strong>Fix:</strong> Always set max_steps (5-10 for most tasks).</p>
                    </div>
                </div>
            </div>

            <h3>üè≠ Production Playbook</h3>
            <div class="production-tips">
                <div class="tip-row">
                    <div class="tip-number">1</div>
                    <div class="tip-content">
                        <strong>Start simple, scale complexity</strong>
                        <p>Begin with basic prompting ‚Üí add CoT if accuracy is low ‚Üí add Self-Consistency for high-stakes ‚Üí consider ToT only for genuinely hard problems. Most production systems don't need ToT.</p>
                    </div>
                </div>
                <div class="tip-row">
                    <div class="tip-number">2</div>
                    <div class="tip-content">
                        <strong>Build a query classifier</strong>
                        <p>Not all queries need the same treatment. A lightweight classifier (or even a regex) can route simple queries to fast paths and complex queries to expensive techniques.</p>
                    </div>
                </div>
                <div class="tip-row">
                    <div class="tip-number">3</div>
                    <div class="tip-content">
                        <strong>Combine techniques strategically</strong>
                        <p>PoT + Self-Consistency: Generate multiple code solutions, vote on outputs. ReAct + Reflexion: Retry failed tool calls with reflection. The techniques compose.</p>
                    </div>
                </div>
                <div class="tip-row">
                    <div class="tip-number">4</div>
                    <div class="tip-content">
                        <strong>Measure what matters</strong>
                        <p>Track: accuracy, latency (p50/p95/p99), cost per query, failure modes. A technique that's +5% accuracy but +1000% cost may not be worth it.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Foundational Papers Section -->
        <section>
            <div class="section-header">
                <div class="line-indicator cot"></div>
                <h2>Chain-of-Thought Line</h2>
            </div>
            <div class="papers-grid">
                <!-- CoT Paper -->
                <div class="paper-card cot" id="card-cot">
                    <div class="paper-header" onclick="toggleCard('card-cot')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">CoT</span>
                                <span class="citation-badge high">üìö 17,700+ citations</span>
                            </div>
                            <h3>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h3>
                            <p class="authors">Wei et al. (inc. Denny Zhou) ‚Ä¢ Google Brain ‚Ä¢ NeurIPS 2022</p>
                            <p class="idea">The foundational paper that started it all. Adding few-shot examples with explicit step-by-step reasoning dramatically boosts performance on arithmetic, symbolic, and commonsense reasoning.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Core Idea: Why This Paper Changed Everything</h4>
                                <p>Before CoT, the standard approach was <strong>direct prompting</strong>: "Q: What is 23 √ó 17? A: 391". The model had to make a single forward pass and hope it had "memorized" enough similar patterns. This paper showed that by asking the model to <em>show its work</em>, you unlock reasoning capabilities that simply don't exist in direct prompting.</p>
                                <div class="key-learning">
                                    <h5>üí° Key Learning</h5>
                                    <p>LLMs don't actually "reason" in a single forward pass‚Äîthey pattern match. CoT works because it breaks complex problems into simpler pattern-matching steps that the model <em>can</em> do in one pass. Each intermediate step is easier than the whole problem.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>How It Works: Step by Step</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Provide Few-Shot Examples with Reasoning</div>
                                            <div class="step-desc">Instead of just showing input‚Üíoutput pairs, show input‚Üíreasoning‚Üíoutput. The model learns the <em>pattern</em> of thinking through problems.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Model Generates Intermediate Steps</div>
                                            <div class="step-desc">When given a new problem, the model follows the demonstrated pattern and generates its own reasoning chain before the answer.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Each Step Becomes Context for the Next</div>
                                            <div class="step-desc">As the model generates each reasoning step, that text becomes part of the context for generating the next step‚Äîeffectively "working memory."</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">4</div>
                                        <div class="step-content">
                                            <div class="step-title">Final Answer Follows from Reasoning</div>
                                            <div class="step-desc">The answer is now a simple extraction from the reasoning chain, not a complex leap from the original problem.</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Example Prompt: Standard vs Chain-of-Thought</h4>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px;">
                                    <div class="example-prompt">
                                        <span class="prompt-label">‚ùå Standard Prompting</span>
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?
A: 11

Q: A juggler has 16 balls. Half are golf balls, and half of the golf balls are blue. How many blue golf balls are there?
A:</div>
                                    <div class="example-prompt">
                                        <span class="prompt-label">‚úì Chain-of-Thought Prompting</span>
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?
A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.

Q: A juggler has 16 balls. Half are golf balls, and half of the golf balls are blue. How many blue golf balls are there?
A:</div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>Standard</th><th>CoT</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>GSM8K (math)</td><td>17.9%</td><td><span class="metric-highlight">58.0%</span></td><td>+40.1%</td></tr>
                                        <tr><td>SVAMP (math)</td><td>58.8%</td><td><span class="metric-highlight">78.2%</span></td><td>+19.4%</td></tr>
                                        <tr><td>ASDiv (math)</td><td>71.3%</td><td><span class="metric-highlight">78.6%</span></td><td>+7.3%</td></tr>
                                        <tr><td>AQuA (algebra)</td><td>25.2%</td><td><span class="metric-highlight">35.8%</span></td><td>+10.6%</td></tr>
                                        <tr><td>StrategyQA</td><td>65.4%</td><td><span class="metric-highlight">73.2%</span></td><td>+7.8%</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>Why It Works: The Theoretical Insight</h4>
                                <p>Transformers are inherently <strong>parallel</strong> architectures‚Äîthey process all tokens simultaneously. This means they can only compute functions in the complexity class TC‚Å∞ (constant depth circuits).</p>
                                <p style="margin-top: 12px;">Many problems (like multi-digit arithmetic) are <strong>inherently serial</strong>‚Äîyou must compute intermediate values before the final answer. CoT effectively gives the transformer "extra layers" through the sequential generation of tokens.</p>
                                <div class="callout-box">
                                    <h5>The Deep Insight</h5>
                                    <p>CoT length should match the problem's "serial depth." A 10-step calculation needs ~10 reasoning steps. This explains why CoT helps arithmetic but barely affects pattern matching.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Key Discoveries</h4>
                                <ul>
                                    <li><strong>Emergent ability:</strong> CoT only helps models ‚â•100B parameters. Smaller models generate plausible-looking but wrong reasoning.</li>
                                    <li><strong>8 examples suffice:</strong> More examples don't help much after 8; the model gets the pattern.</li>
                                    <li><strong>Quality over quantity:</strong> Better reasoning examples matter more than more examples.</li>
                                    <li><strong>Zero-shot works:</strong> Just adding "Let's think step by step" works (but worse than few-shot).</li>
                                    <li><strong>Errors cascade:</strong> One wrong step usually means wrong final answer.</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Limitations & When NOT to Use</h4>
                                <ul>
                                    <li><strong>Simple lookups:</strong> "What is the capital of France?" doesn't need reasoning.</li>
                                    <li><strong>Pattern matching:</strong> Tasks solvable by retrieval don't benefit.</li>
                                    <li><strong>Small models:</strong> Below 60B parameters, CoT often hurts performance.</li>
                                    <li><strong>Time-sensitive apps:</strong> Generating reasoning adds latency and cost.</li>
                                    <li><strong>Factual questions:</strong> CoT can confabulate convincing-but-wrong reasoning.</li>
                                </ul>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Practical Implementation Tips</h4>
                                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 12px;">
                                    <div class="key-learning">
                                        <h5>üéØ Tip 1: Match Step Granularity</h5>
                                        <p>Your example reasoning should be at the right granularity. Too coarse = model skips important steps. Too fine = unnecessary verbosity and cost.</p>
                                    </div>
                                    <div class="key-learning">
                                        <h5>üéØ Tip 2: Include Diverse Examples</h5>
                                        <p>Cover different reasoning patterns in your examples. If all examples use the same approach, the model won't generalize well.</p>
                                    </div>
                                    <div class="key-learning">
                                        <h5>üéØ Tip 3: Verify the Reasoning</h5>
                                        <p>A correct final answer doesn't mean correct reasoning. Check intermediate steps‚Äîbad reasoning can get lucky.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2201.11903" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://arxiv.org/pdf/2201.11903.pdf" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path><polyline points="7 10 12 15 17 10"></polyline><line x1="12" y1="15" x2="12" y2="3"></line></svg>
                                PDF
                            </a>
                            <a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                                Google AI Blog
                            </a>
                            <a href="https://www.youtube.com/watch?v=_K-bPD2K5JY" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polygon points="5 3 19 12 5 21 5 3"></polygon></svg>
                                Video Explanation
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Self-Consistency Paper -->
                <div class="paper-card cot" id="card-self-consistency">
                    <div class="paper-header" onclick="toggleCard('card-self-consistency')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Self-Consistency</span>
                                <span class="citation-badge high">üìö 4,200+ citations</span>
                            </div>
                            <h3>Self-Consistency Improves Chain of Thought Reasoning in Language Models</h3>
                            <p class="authors">Wang et al. (inc. Denny Zhou) ‚Ä¢ Google Research ‚Ä¢ ICLR 2023</p>
                            <p class="idea">Instead of greedy decoding, sample multiple diverse reasoning paths and take a majority vote. Turns CoT into an ensemble method with significant accuracy gains.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Core Insight: Wisdom of Crowds for Reasoning</h4>
                                <p>Self-Consistency is beautifully simple: <strong>correct reasoning paths are more likely to agree on the answer than incorrect ones</strong>. If you ask a model to solve a problem multiple times with some randomness, the correct answer should appear more often than any particular wrong answer.</p>
                                <div class="key-learning">
                                    <h5>üí° Key Learning</h5>
                                    <p>This technique turns CoT into an ensemble method. Different reasoning paths are like different "voters"‚Äîerrors are random and cancel out, while the truth converges. It's the same principle behind random forests and ensemble learning.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>How It Works: The Algorithm</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Sample Multiple Reasoning Paths</div>
                                            <div class="step-desc">Instead of greedy decoding (temperature=0), use temperature 0.5-0.7 to generate diverse reasoning chains. Sample N times (typically 5-40).</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Extract Final Answers</div>
                                            <div class="step-desc">Parse the final answer from each reasoning chain. The reasoning paths may differ wildly, but we only care about the final answer.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Majority Vote</div>
                                            <div class="step-desc">Return the most frequent answer. Ties can be broken randomly or by taking the first occurrence.</div>
                                        </div>
                                    </div>
                                </div>
                                <div class="technique-diagram">
                                    <span class="node">Problem</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Path 1: ... ‚Üí 42</span><br>
                                    <span class="node">Problem</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Path 2: ... ‚Üí 42</span><br>
                                    <span class="node">Problem</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Path 3: ... ‚Üí 37</span><br>
                                    <span class="node">Problem</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Path 4: ... ‚Üí 42</span><br>
                                    <span class="arrow">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span><br>
                                    <span class="node" style="background: rgba(220, 136, 80, 0.2);">Majority Vote: 42 (3/4)</span>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>CoT</th><th>Self-Cons.</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>GSM8K</td><td>58.0%</td><td><span class="metric-highlight">74.4%</span></td><td>+16.4%</td></tr>
                                        <tr><td>SVAMP</td><td>78.2%</td><td><span class="metric-highlight">86.6%</span></td><td>+8.4%</td></tr>
                                        <tr><td>AQuA</td><td>35.8%</td><td><span class="metric-highlight">48.0%</span></td><td>+12.2%</td></tr>
                                        <tr><td>StrategyQA</td><td>73.2%</td><td><span class="metric-highlight">79.1%</span></td><td>+5.9%</td></tr>
                                        <tr><td>ARC-c</td><td>85.2%</td><td><span class="metric-highlight">88.7%</span></td><td>+3.5%</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>Why It Works: The Math</h4>
                                <p>Assume the model has probability <em>p</em> of generating a correct reasoning path. With majority voting over <em>n</em> samples, the probability of a correct final answer approaches 1 as <em>n</em> increases (if p > 0.5).</p>
                                <div class="callout-box">
                                    <h5>The Statistics</h5>
                                    <p>If each sample has 60% accuracy independently, 5 samples give ~68% accuracy, 10 samples give ~75%, and 40 samples give ~83%. This is the <strong>Condorcet jury theorem</strong> applied to reasoning.</p>
                                </div>
                                <p style="margin-top: 12px;">Crucially, different reasoning paths make <strong>different mistakes</strong>. Path A might misread a number, Path B might use wrong formula, but the correct answer emerges from the noise.</p>
                            </div>

                            <div class="expanded-section">
                                <h4>The Scaling Curve</h4>
                                <p>Performance scales logarithmically with samples:</p>
                                <ul>
                                    <li><strong>1 sample:</strong> Baseline CoT accuracy</li>
                                    <li><strong>5 samples:</strong> ~70% of potential gain</li>
                                    <li><strong>10 samples:</strong> ~85% of potential gain</li>
                                    <li><strong>40 samples:</strong> ~95% of potential gain</li>
                                    <li><strong>100+ samples:</strong> Diminishing returns</li>
                                </ul>
                                <div class="key-learning">
                                    <h5>üí° Practical Insight</h5>
                                    <p>For production, 5-10 samples is the sweet spot‚Äîmost of the accuracy gain with manageable cost. Use 40+ only when accuracy is critical and cost isn't.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Implementation Details</h4>
                                <div class="code-block">
<span class="keyword">def</span> <span class="function">self_consistency</span>(prompt, n_samples=10, temp=0.7):
    answers = []
    <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples):
        response = llm.generate(prompt, temperature=temp)
        answer = extract_answer(response)
        answers.append(answer)

    <span class="comment"># Majority vote</span>
    <span class="keyword">from</span> collections <span class="keyword">import</span> Counter
    vote = Counter(answers).most_common(1)[0][0]
    <span class="keyword">return</span> vote</div>
                            </div>

                            <div class="expanded-section">
                                <h4>Critical Parameters</h4>
                                <ul>
                                    <li><strong>Temperature 0.5-0.7:</strong> Too low = identical paths, too high = nonsense</li>
                                    <li><strong>Top-p 0.95:</strong> Helps diversity without degeneracy</li>
                                    <li><strong>Parallel sampling:</strong> All samples can run concurrently</li>
                                    <li><strong>Answer extraction:</strong> Must reliably parse final answer (regex, delimiter)</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Limitations & Gotchas</h4>
                                <ul>
                                    <li><strong>Cost:</strong> 10x samples = 10x tokens = 10x cost</li>
                                    <li><strong>Systematic errors:</strong> If the model is systematically wrong, voting won't help</li>
                                    <li><strong>Answer space:</strong> Works best when answers are discrete (numbers, multiple choice)</li>
                                    <li><strong>Open-ended tasks:</strong> Hard to vote on free-form text generation</li>
                                    <li><strong>Parse failures:</strong> Must handle cases where answer can't be extracted</li>
                                </ul>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Advanced Variations</h4>
                                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 12px;">
                                    <div class="key-learning">
                                        <h5>üìä Weighted Voting</h5>
                                        <p>Weight votes by model confidence (log probability of the reasoning chain). Paths the model is more "sure" about get more weight.</p>
                                    </div>
                                    <div class="key-learning">
                                        <h5>üîÑ Verifier Models</h5>
                                        <p>Train a separate model to score reasoning quality. Use scores instead of raw votes. OpenAI's approach for math reasoning.</p>
                                    </div>
                                    <div class="key-learning">
                                        <h5>üéØ Best-of-N</h5>
                                        <p>Instead of voting, use a reward model to pick the best single response. More flexible for open-ended tasks.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2203.11171" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://openreview.net/forum?id=1PL1NIMMrw" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg>
                                OpenReview (ICLR)
                            </a>
                            <a href="https://github.com/AGI-Edgerunners/Self-Consistency" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                Implementation
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Least-to-Most Paper -->
                <div class="paper-card cot" id="card-l2m">
                    <div class="paper-header" onclick="toggleCard('card-l2m')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Least-to-Most</span>
                                <span class="citation-badge">üìö 1,400+ citations</span>
                            </div>
                            <h3>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</h3>
                            <p class="authors">Zhou et al. ‚Ä¢ Google Research ‚Ä¢ ICLR 2023</p>
                            <p class="idea">Decompose complex problems into simpler subproblems, solve from easiest to hardest. Each solution feeds into the next, enabling better generalization to harder problems.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Key Insight: Structured Decomposition Beats Linear Reasoning</h4>
                                <p>CoT asks the model to think through a problem in one shot‚Äîit figures out the structure while solving. Least-to-Most <strong>separates decomposition from solving</strong>: first figure out what subproblems exist, then solve them in order from simplest to most complex.</p>
                                <div class="key-learning">
                                    <h5>üí° Key Learning</h5>
                                    <p>The magic is in the <strong>ordering</strong>: solving easier subproblems first provides scaffolding for harder ones. Each solution becomes context for the next, building up to the final answer. This mimics how humans tackle complex problems‚Äîbreak them down, start simple.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Two-Stage Process</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Decomposition Stage</div>
                                            <div class="step-desc">Ask: "To solve [original problem], what subproblems do we need to solve first?" The model outputs an ordered list from simplest to most complex.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Sequential Solving Stage</div>
                                            <div class="step-desc">Solve subproblem 1 ‚Üí add solution to context ‚Üí solve subproblem 2 with that context ‚Üí repeat until the final (hardest) subproblem is solved.</div>
                                        </div>
                                    </div>
                                </div>
                                <div class="technique-diagram">
                                    <span class="node">Original Problem</span><br>
                                    <span class="arrow">‚Üì Decompose</span><br>
                                    <span class="node">Sub-1 (easy)</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Sub-2</span> <span class="arrow">‚Üí</span>
                                    <span class="node">Sub-3 (hard)</span><br>
                                    <span class="arrow">‚Üì Solve sequentially</span><br>
                                    <span class="node">Solve Sub-1</span> <span class="arrow">‚Üí</span>
                                    <span class="node">+context ‚Üí Solve Sub-2</span> <span class="arrow">‚Üí</span>
                                    <span class="node">+context ‚Üí Solve Sub-3</span><br>
                                    <span class="arrow">‚Üì</span><br>
                                    <span class="node" style="background: rgba(220, 136, 80, 0.2);">Final Answer</span>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Example: Symbol Mapping (SCAN)</h4>
                                <div class="example-prompt">
                                    <span class="prompt-label">Task</span>
"jump around left twice" ‚Üí actions

<span class="prompt-label">Stage 1: Decomposition</span>
Q: "jump around left twice" can be solved by first solving what subproblems?
A: We need to solve:
   1. "left" (simplest)
   2. "jump left"
   3. "jump around left"
   4. "jump around left twice" (original)

<span class="prompt-label">Stage 2: Solving</span>
Q: "left" ‚Üí ?
A: TURN LEFT

Q: "left" means TURN LEFT. "jump left" ‚Üí ?
A: TURN LEFT JUMP

Q: "left" means TURN LEFT. "jump left" means TURN LEFT JUMP.
   "jump around left" ‚Üí ?
A: TURN LEFT JUMP TURN LEFT JUMP TURN LEFT JUMP TURN LEFT JUMP

Q: [all previous context] "jump around left twice" ‚Üí ?
A: [full solution]</div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>CoT</th><th>Least-to-Most</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>SCAN (length gen.)</td><td>16.0%</td><td><span class="metric-highlight">99.7%</span></td><td>+83.7%</td></tr>
                                        <tr><td>DROP (reading comp.)</td><td>78.7%</td><td><span class="metric-highlight">82.3%</span></td><td>+3.6%</td></tr>
                                        <tr><td>GSM8K (math)</td><td>58.0%</td><td><span class="metric-highlight">62.4%</span></td><td>+4.4%</td></tr>
                                        <tr><td>CFQ (compositional)</td><td>33.1%</td><td><span class="metric-highlight">94.3%</span></td><td>+61.2%</td></tr>
                                    </tbody>
                                </table>
                                <div class="callout-box">
                                    <h5>The SCAN Result is Remarkable</h5>
                                    <p>CoT completely fails at length generalization (16%)‚Äîif the test sequence is longer than training examples, it can't cope. L2M achieves 99.7% by learning to decompose rather than memorize.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Why Length Generalization Works</h4>
                                <p>Standard CoT fails on problems longer than training examples because it learns to match <em>patterns</em>, not <em>procedures</em>. L2M forces the model to learn <strong>compositional rules</strong>:</p>
                                <ul>
                                    <li><strong>Base cases:</strong> Simple primitives like "left" ‚Üí TURN LEFT</li>
                                    <li><strong>Composition rules:</strong> How to combine primitives</li>
                                    <li><strong>Recursive application:</strong> Apply rules at any depth</li>
                                </ul>
                                <div class="key-learning">
                                    <h5>üí° Key Insight</h5>
                                    <p>L2M essentially teaches the model a <strong>recursive algorithm</strong> through examples rather than a fixed pattern. This is why it generalizes to longer inputs‚Äîthe algorithm works at any length.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>When to Use Least-to-Most</h4>
                                <ul>
                                    <li><strong>Compositional tasks:</strong> Where the answer is built from smaller pieces</li>
                                    <li><strong>Length generalization:</strong> Test inputs longer than training</li>
                                    <li><strong>Hierarchical problems:</strong> Natural parent-child structure</li>
                                    <li><strong>Complex word problems:</strong> Multiple interdependent steps</li>
                                    <li><strong>Symbolic reasoning:</strong> Rule-based transformations</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Comparison: CoT vs Least-to-Most</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Aspect</th><th>Chain-of-Thought</th><th>Least-to-Most</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Passes</td><td>Single pass</td><td>Two-pass (decompose + solve)</td></tr>
                                        <tr><td>Structure</td><td>Implicit</td><td>Explicit decomposition</td></tr>
                                        <tr><td>Context growth</td><td>Linear</td><td>Grows with each subproblem</td></tr>
                                        <tr><td>Length gen.</td><td>Poor</td><td><span class="metric-highlight">Excellent</span></td></tr>
                                        <tr><td>Cost</td><td>Lower</td><td>Higher (multiple calls)</td></tr>
                                        <tr><td>Best for</td><td>Simple reasoning</td><td>Compositional tasks</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>Implementation Considerations</h4>
                                <ul>
                                    <li><strong>Decomposition prompt:</strong> "To solve X, what subproblems need to be solved first?"</li>
                                    <li><strong>Ordering is critical:</strong> Must go from easy ‚Üí hard, not arbitrary</li>
                                    <li><strong>Context accumulation:</strong> Each solution is added to context for next subproblem</li>
                                    <li><strong>Multiple API calls:</strong> One for decomposition, one per subproblem</li>
                                    <li><strong>Context length:</strong> Can grow large‚Äîmay need truncation strategy</li>
                                </ul>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Limitations</h4>
                                <div class="callout-box warning">
                                    <h5>When NOT to Use</h5>
                                    <p><strong>Simple problems:</strong> Overhead isn't worth it. <strong>Non-compositional tasks:</strong> If the problem doesn't decompose naturally, L2M won't help. <strong>Latency-sensitive:</strong> Multiple API calls add delay. <strong>Ambiguous decomposition:</strong> If there's no clear subproblem structure, the decomposition stage may fail.</p>
                                </div>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2205.10625" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://openreview.net/forum?id=WZH7099tgfM" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg>
                                OpenReview (ICLR)
                            </a>
                        </div>
                    </div>
                </div>

                <!-- CoT Without Prompting -->
                <div class="paper-card cot" id="card-cot-noprompt">
                    <div class="paper-header" onclick="toggleCard('card-cot-noprompt')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">CoT w/o Prompting</span>
                                <span class="citation-badge">üìö 168 citations</span>
                            </div>
                            <h3>Chain-of-Thought Reasoning Without Prompting</h3>
                            <p class="authors">Wang & Zhou et al. ‚Ä¢ Google DeepMind ‚Ä¢ 2024</p>
                            <p class="idea">Discovers that CoT reasoning can emerge naturally without demonstrations by decoding with alternative top-k tokens. The model already "knows" how to reason‚Äîyou just need to find it.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Surprising Discovery: Models Already Know How to Reason</h4>
                                <p>The standard assumption was that CoT prompting <em>teaches</em> the model to reason. This paper overturns that: <strong>the reasoning capability already exists in pretrained models</strong>‚Äîit's just not activated by default greedy decoding.</p>
                                <div class="key-learning">
                                    <h5>üí° The Key Insight</h5>
                                    <p>When you decode greedily (always pick the highest probability token), the model often jumps straight to an answer. But if you look at the 2nd, 3rd, or 10th most likely next token, you often find the start of a reasoning chain. The model "knows" it should reason‚Äîit just doesn't do it by default.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>How It Works: CoT-Decoding</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Ask a Question (No CoT Prompt)</div>
                                            <div class="step-desc">Just ask "Q: What is 15 √ó 7?" without any "think step by step" instruction.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Explore Top-k First Tokens</div>
                                            <div class="step-desc">Instead of greedy decode, look at the top k (e.g., 10) most likely first tokens. Some will be direct answers ("105"), others will be reasoning starters ("Let", "First", "15").</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Continue Each Path</div>
                                            <div class="step-desc">Decode each path to completion. The paths that start with reasoning tokens naturally generate CoT-style reasoning.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">4</div>
                                        <div class="step-content">
                                            <div class="step-title">Select Based on Confidence</div>
                                            <div class="step-desc">Answers generated via CoT paths tend to have higher confidence. Select the path where the model is most confident in the final answer.</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>What They Found in the Decoding Space</h4>
                                <div class="technique-diagram">
                                    Q: "What is 15 √ó 7?"<br><br>
                                    <span class="node">Top-1: "105"</span> (direct answer)<br>
                                    <span class="node">Top-2: "The"</span> ‚Üí "The answer is 105"<br>
                                    <span class="node">Top-3: "15"</span> ‚Üí "15 √ó 7 = 105"<br>
                                    <span class="node">Top-5: "Let"</span> ‚Üí "Let me calculate: 15 √ó 7 = 105" ‚úì<br>
                                    <span class="node">Top-8: "First"</span> ‚Üí "First, 15 √ó 7... = 105" ‚úì
                                </div>
                                <p style="margin-top: 12px;">The reasoning paths exist‚Äîthey're just not the highest probability by default. Prompting with "think step by step" shifts probability mass toward these paths.</p>
                            </div>

                            <div class="expanded-section">
                                <h4>Key Experimental Results</h4>
                                <ul>
                                    <li><strong>CoT paths exist:</strong> ~40% of questions had a CoT path in top-10 alternatives</li>
                                    <li><strong>Correlation with correctness:</strong> When CoT path exists, the answer is more often correct</li>
                                    <li><strong>Higher confidence:</strong> Model assigns higher probability to final answer when CoT is present</li>
                                    <li><strong>No prompting needed:</strong> The same reasoning emerges without any "think step by step" instruction</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Why This Matters: Deep Implications</h4>
                                <div class="key-learning">
                                    <h5>üí° Implication 1: Reasoning is Emergent</h5>
                                    <p>Models learn to reason from pretraining data (math textbooks, Stack Overflow, etc.). CoT prompting doesn't teach reasoning‚Äîit activates existing capability.</p>
                                </div>
                                <div class="key-learning">
                                    <h5>üí° Implication 2: Decoding Strategy Matters</h5>
                                    <p>Greedy decoding may be leaving performance on the table. Alternative decoding strategies (beam search variants, top-k exploration) could unlock hidden capabilities.</p>
                                </div>
                                <div class="key-learning">
                                    <h5>üí° Implication 3: Explains Emergence</h5>
                                    <p>This may explain why CoT only works at scale: smaller models may not have learned reasoning from pretraining data, so there's no latent capability to activate.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Practical Applications</h4>
                                <ul>
                                    <li><strong>Confidence calibration:</strong> Presence of CoT in alternatives indicates the model is confident</li>
                                    <li><strong>Automatic CoT detection:</strong> Check if reasoning paths exist in top-k to decide if a question needs more careful handling</li>
                                    <li><strong>Better decoding:</strong> Can bias decoding toward reasoning tokens for improved accuracy</li>
                                    <li><strong>Research direction:</strong> Opens new research into decoding-time interventions</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Limitations</h4>
                                <ul>
                                    <li><strong>Compute intensive:</strong> Exploring top-k requires k√ó more decoding</li>
                                    <li><strong>Not always present:</strong> CoT paths only exist ~40% of the time</li>
                                    <li><strong>Smaller models:</strong> Effect is weaker in smaller models (they may not have learned reasoning)</li>
                                    <li><strong>Complex questions:</strong> For very complex problems, even the CoT paths may be wrong</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2402.10200" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://www.semanticscholar.org/paper/Chain-of-Thought-Reasoning-Without-Prompting-Wang-Zhou/c8b1206ef8e6fdebd3b9ad2165937256ab8" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path><line x1="12" y1="17" x2="12.01" y2="17"></line></svg>
                                Semantic Scholar
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div class="section-header">
                <div class="line-indicator action"></div>
                <h2>Action & Agents Line</h2>
            </div>
            <div class="papers-grid">
                <!-- ReAct Paper -->
                <div class="paper-card action" id="card-react">
                    <div class="paper-header" onclick="toggleCard('card-react')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">ReAct</span>
                                <span class="citation-badge high">üìö 5,886 citations</span>
                            </div>
                            <h3>ReAct: Synergizing Reasoning and Acting in Language Models</h3>
                            <p class="authors">Yao et al. ‚Ä¢ Princeton + Google ‚Ä¢ ICLR 2023</p>
                            <p class="idea">The foundation of modern AI agents. Interleaves reasoning traces with actions (search, lookup, etc.), allowing models to plan, act, observe, and revise. Thought ‚Üí Action ‚Üí Observation loops.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Foundational Insight: Reasoning and Acting Must Be Interleaved</h4>
                                <p>Before ReAct, there were two separate paradigms: <strong>Chain-of-Thought</strong> (pure reasoning, no actions) and <strong>Action-Only</strong> (just execute actions, no explicit reasoning). Both had limitations‚ÄîCoT couldn't gather new information, and action-only was uninterpretable and error-prone.</p>
                                <div class="key-learning">
                                    <h5>üí° The Key Learning</h5>
                                    <p>Humans don't think-then-act or act-then-think‚Äîwe <strong>interleave</strong> them continuously. "I need to find X" ‚Üí search ‚Üí "Found Y, not X" ‚Üí revise plan ‚Üí search again. ReAct captures this interleaved process, making agents both more capable and more interpretable.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The ReAct Loop: Thought ‚Üí Action ‚Üí Observation</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">T</div>
                                        <div class="step-content">
                                            <div class="step-title">Thought</div>
                                            <div class="step-desc">The model reasons about what to do next: "I need to find when Obama was born." This is explicit internal reasoning.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">A</div>
                                        <div class="step-content">
                                            <div class="step-title">Action</div>
                                            <div class="step-desc">The model chooses an action from the available toolkit: Search[Barack Obama], Lookup[born], Calculate[2024-1961], etc.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">O</div>
                                        <div class="step-content">
                                            <div class="step-title">Observation</div>
                                            <div class="step-desc">The environment returns a result: "Barack Obama was born August 4, 1961..." This feeds back into the next Thought.</div>
                                        </div>
                                    </div>
                                </div>
                                <div class="example-prompt">
                                    <span class="prompt-label">Example ReAct Trace</span>
Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?

Thought 1: I need to search Colorado orogeny to find the area that the eastern sector extends into.
Action 1: Search[Colorado orogeny]
Observation 1: The Colorado orogeny was an episode of mountain building... The eastern sector extends into the High Plains.

Thought 2: The eastern sector extends into the High Plains. I need to search High Plains and find its elevation range.
Action 2: Search[High Plains]
Observation 2: High Plains refers to one of two distinct land regions: the High Plains in the United States...elevation range of 1,800 to 7,000 ft.

Thought 3: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.
Action 3: Finish[1,800 to 7,000 ft]</div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>CoT Only</th><th>Act Only</th><th>ReAct</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>HotpotQA (QA)</td><td>28%</td><td>25%</td><td><span class="metric-highlight">34%</span></td></tr>
                                        <tr><td>FEVER (fact-check)</td><td>56%</td><td>58%</td><td><span class="metric-highlight">64%</span></td></tr>
                                        <tr><td>ALFWorld (games)</td><td>N/A</td><td>45%</td><td><span class="metric-highlight">71%</span></td></tr>
                                        <tr><td>WebShop (shopping)</td><td>N/A</td><td>30%</td><td><span class="metric-highlight">40%</span></td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>Why Interleaving Works</h4>
                                <ul>
                                    <li><strong>Reasoning grounds actions:</strong> Thoughts prevent random or hallucinated actions</li>
                                    <li><strong>Actions ground reasoning:</strong> Real observations prevent hallucinated facts</li>
                                    <li><strong>Error recovery:</strong> When observations don't match expectations, thoughts can revise the plan</li>
                                    <li><strong>Interpretability:</strong> The thought trace shows exactly why each action was taken</li>
                                </ul>
                                <div class="key-learning">
                                    <h5>üí° The Synergy</h5>
                                    <p>CoT alone hallucinates facts it doesn't know. Act-only makes random mistakes with no way to recover. ReAct combines the planning of CoT with the grounding of actions‚Äîeach compensates for the other's weakness.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Standard Action Space</h4>
                                <div class="code-block">
<span class="comment"># ReAct's original action space for QA tasks:</span>

Search[query]      <span class="comment"># Search Wikipedia for a topic</span>
Lookup[keyword]    <span class="comment"># Find keyword in current page</span>
Finish[answer]     <span class="comment"># Complete task with final answer</span>

<span class="comment"># Extended action spaces in practice:</span>

Calculate[expr]    <span class="comment"># Evaluate mathematical expression</span>
Code[python]       <span class="comment"># Execute Python code</span>
Browse[url]        <span class="comment"># Navigate to a URL</span>
API[endpoint, params]  <span class="comment"># Call external API</span></div>
                            </div>

                            <div class="expanded-section">
                                <h4>The Modern Impact: Every Agent Framework Uses This</h4>
                                <ul>
                                    <li><strong>LangChain Agents:</strong> Direct implementation of ReAct loop</li>
                                    <li><strong>AutoGPT/BabyAGI:</strong> Extended ReAct with memory and task decomposition</li>
                                    <li><strong>OpenAI Function Calling:</strong> Structured version of Action step</li>
                                    <li><strong>Claude Tools:</strong> Same pattern‚Äîinterleave reasoning with tool use</li>
                                    <li><strong>Microsoft Copilot:</strong> ReAct-style reasoning for code actions</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Implementation Pattern</h4>
                                <div class="code-block">
<span class="keyword">def</span> <span class="function">react_loop</span>(question, tools, max_steps=10):
    context = f<span class="string">"Question: {question}\n"</span>

    <span class="keyword">for</span> step <span class="keyword">in</span> range(max_steps):
        <span class="comment"># Generate Thought + Action</span>
        response = llm.generate(context + <span class="string">"Thought:"</span>)
        thought, action = parse_thought_action(response)
        context += f<span class="string">"Thought {step}: {thought}\nAction {step}: {action}\n"</span>

        <span class="comment"># Execute action and get observation</span>
        <span class="keyword">if</span> action.startswith(<span class="string">"Finish"</span>):
            <span class="keyword">return</span> extract_answer(action)

        observation = tools.execute(action)
        context += f<span class="string">"Observation {step}: {observation}\n"</span>

    <span class="keyword">return</span> <span class="string">"Failed to find answer"</span></div>
                            </div>

                            <div class="expanded-section">
                                <h4>Common Failure Modes</h4>
                                <ul>
                                    <li><strong>Infinite loops:</strong> Agent keeps searching without finishing (need max steps)</li>
                                    <li><strong>Hallucinated actions:</strong> Agent calls tools that don't exist (need validation)</li>
                                    <li><strong>Ignored observations:</strong> Agent ignores what it finds and proceeds with prior beliefs</li>
                                    <li><strong>Premature finish:</strong> Agent finishes before gathering enough info</li>
                                    <li><strong>Overthinking:</strong> Too many thoughts without action slows progress</li>
                                </ul>
                                <div class="callout-box warning">
                                    <h5>Production Tip</h5>
                                    <p>Always set max_steps and validate action format. Most failures come from agents getting stuck in loops or calling invalid actions. Structured output (JSON) for actions helps reliability.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>ReAct vs Alternatives</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Aspect</th><th>CoT Only</th><th>Act Only</th><th>ReAct</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Can use tools?</td><td>‚ùå No</td><td>‚úì Yes</td><td>‚úì Yes</td></tr>
                                        <tr><td>Interpretable?</td><td>‚úì Yes</td><td>‚ùå No</td><td>‚úì Yes</td></tr>
                                        <tr><td>Error recovery?</td><td>‚ùå No</td><td>‚ùå No</td><td>‚úì Yes</td></tr>
                                        <tr><td>Hallucination risk</td><td>High</td><td>Low</td><td>Low</td></tr>
                                        <tr><td>Token cost</td><td>Low</td><td>Low</td><td>Medium</td></tr>
                                        <tr><td>Latency</td><td>Low</td><td>Medium</td><td>High</td></tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2210.03629" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://react-lm.github.io/" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                                Project Page
                            </a>
                            <a href="https://github.com/ysymyth/ReAct" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                GitHub
                            </a>
                            <a href="https://blog.research.google/2022/11/react-synergizing-reasoning-and-acting.html" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                                Google AI Blog
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Reflexion Paper -->
                <div class="paper-card action" id="card-reflexion">
                    <div class="paper-header" onclick="toggleCard('card-reflexion')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Reflexion</span>
                                <span class="citation-badge high">üìö 2,855 citations</span>
                            </div>
                            <h3>Reflexion: Language Agents with Verbal Reinforcement Learning</h3>
                            <p class="authors">Shinn et al. ‚Ä¢ Northeastern + MIT ‚Ä¢ NeurIPS 2023</p>
                            <p class="idea">Agents learn from failure by reflecting in natural language. After a failed attempt, the agent generates self-critique and stores it as memory for future tries. Verbal RL without weight updates.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Key Insight: Learning from Failure in Natural Language</h4>
                                <p>Traditional RL uses scalar rewards (success/failure, +1/-1) to update model weights. But LLMs can do something remarkable: they can <strong>reflect on why they failed in natural language</strong> and use that as context for the next attempt‚Äîno weight updates needed.</p>
                                <div class="key-learning">
                                    <h5>üí° The Breakthrough</h5>
                                    <p>Instead of training: "Trial 1 failed (reward=-1)", Reflexion does: "Trial 1 failed because I forgot to check the edge case where n=0. Next time, I should add explicit handling for empty inputs." This rich linguistic signal is far more informative than a scalar reward.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Reflexion Loop</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Act: Make an Attempt</div>
                                            <div class="step-desc">The agent tries to complete the task (write code, navigate environment, answer question).</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Evaluate: Get Feedback</div>
                                            <div class="step-desc">Run tests, check answer, or get environment feedback. Binary (pass/fail) or detailed error messages.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Reflect: Analyze Failure</div>
                                            <div class="step-desc">Generate a natural language reflection: "What went wrong? Why? What should I do differently?"</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">4</div>
                                        <div class="step-content">
                                            <div class="step-title">Store: Add to Memory</div>
                                            <div class="step-desc">Store the reflection in episodic memory. This persists across attempts and tasks.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">5</div>
                                        <div class="step-content">
                                            <div class="step-title">Retry: Attempt with Context</div>
                                            <div class="step-desc">Try again with reflections in context. The agent now "remembers" what not to do.</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Example: Coding Task with Reflexion</h4>
                                <div class="example-prompt">
                                    <span class="prompt-label">Trial 1</span>
Task: Write a function to find the longest palindromic substring.

def longest_palindrome(s):
    # My attempt
    for length in range(len(s), 0, -1):
        for i in range(len(s) - length + 1):
            substr = s[i:i+length]
            if substr == substr[::-1]:
                return substr

Test Result: FAILED - Test case "" expected "", got None

<span class="prompt-label">Reflection</span>
I failed because my function doesn't handle the empty string case. When s is empty, the for loop doesn't execute and None is returned implicitly. I should add a check for empty input at the start.

<span class="prompt-label">Trial 2 (with reflection in context)</span>
def longest_palindrome(s):
    if not s:  # Handle empty string
        return ""
    for length in range(len(s), 0, -1):
        ...

Test Result: PASSED ‚úì</div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>Without Reflexion</th><th>With Reflexion</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>HumanEval (code)</td><td>67.0%</td><td><span class="metric-highlight">91.0%</span></td><td>+24.0%</td></tr>
                                        <tr><td>MBPP (code)</td><td>70.0%</td><td><span class="metric-highlight">77.1%</span></td><td>+7.1%</td></tr>
                                        <tr><td>ALFWorld (games)</td><td>75%</td><td><span class="metric-highlight">97%</span></td><td>+22%</td></tr>
                                        <tr><td>HotpotQA (QA)</td><td>35%</td><td><span class="metric-highlight">49%</span></td><td>+14%</td></tr>
                                        <tr><td>WebShop (shopping)</td><td>40%</td><td><span class="metric-highlight">59%</span></td><td>+19%</td></tr>
                                    </tbody>
                                </table>
                                <div class="callout-box">
                                    <h5>The HumanEval Result</h5>
                                    <p>91% pass@1 on HumanEval with GPT-4 was state-of-the-art at publication‚Äîachieved purely through reflection, no fine-tuning. This shows how much performance is left on the table without iterative refinement.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Memory Architecture</h4>
                                <ul>
                                    <li><strong>Short-term memory:</strong> Current task trajectory (actions taken, observations received)</li>
                                    <li><strong>Episodic memory:</strong> Accumulated reflections from past failures</li>
                                    <li><strong>Semantic memory:</strong> General knowledge (comes from LLM pretraining)</li>
                                </ul>
                                <div class="key-learning">
                                    <h5>üí° Design Insight</h5>
                                    <p>Reflections are stored as natural language "lessons learned." Unlike embeddings or weights, they're human-readable and can be curated/edited. You can even manually add reflections to bootstrap learning.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Why It's "Verbal RL"</h4>
                                <p>Reflexion mirrors key RL concepts but in language:</p>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>RL Concept</th><th>Reflexion Equivalent</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Reward signal</td><td>Success/failure feedback</td></tr>
                                        <tr><td>Policy gradient</td><td>Natural language reflection</td></tr>
                                        <tr><td>Experience replay</td><td>Episodic memory of reflections</td></tr>
                                        <tr><td>Exploration</td><td>Different approaches in retries</td></tr>
                                        <tr><td>Weight updates</td><td>Context updates (no training)</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>Implementation Tips</h4>
                                <ul>
                                    <li><strong>Reflection prompt:</strong> "Given the error/feedback above, what went wrong and how should I approach this differently?"</li>
                                    <li><strong>Memory management:</strong> Keep most recent N reflections, summarize older ones</li>
                                    <li><strong>Max retries:</strong> 2-3 iterations usually sufficient; more rarely helps</li>
                                    <li><strong>Task-specific feedback:</strong> Code tasks get test output; QA gets ground truth comparison</li>
                                    <li><strong>Reflection quality:</strong> More specific reflections work better than generic ones</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Limitations</h4>
                                <ul>
                                    <li><strong>Need for feedback:</strong> Requires some evaluation signal (tests, oracle, etc.)</li>
                                    <li><strong>Systematic errors:</strong> If model doesn't know the right approach, reflection won't help</li>
                                    <li><strong>Compute cost:</strong> Multiple attempts per task increases cost</li>
                                    <li><strong>Latency:</strong> Sequential retries add time</li>
                                    <li><strong>Quality ceiling:</strong> Eventually converges‚Äîmore retries don't always help</li>
                                </ul>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Reflexion vs Other Self-Improvement Methods</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Method</th><th>Requires Training?</th><th>Multi-attempt?</th><th>Memory?</th><th>Best For</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Self-Consistency</td><td>‚ùå</td><td>Parallel</td><td>‚ùå</td><td>Answer selection</td></tr>
                                        <tr><td>Self-Refine</td><td>‚ùå</td><td>Sequential</td><td>‚ùå</td><td>Output polish</td></tr>
                                        <tr><td><strong>Reflexion</strong></td><td>‚ùå</td><td>Sequential</td><td>‚úì</td><td>Learning from failure</td></tr>
                                        <tr><td>RLHF</td><td>‚úì</td><td>N/A</td><td>Weights</td><td>General improvement</td></tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2303.11366" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://github.com/noahshinn/reflexion" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                GitHub
                            </a>
                            <a href="https://www.youtube.com/watch?v=5yYlz_XPHCY" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polygon points="5 3 19 12 5 21 5 3"></polygon></svg>
                                Video Walkthrough
                            </a>
                            <a href="https://nanothoughts.substack.com/p/reflecting-on-reflexion" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                                Blog Post
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div class="section-header">
                <div class="line-indicator tree"></div>
                <h2>Tree & Search Line</h2>
            </div>
            <div class="papers-grid">
                <!-- ToT Paper -->
                <div class="paper-card tree" id="card-tot">
                    <div class="paper-header" onclick="toggleCard('card-tot')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">ToT</span>
                                <span class="citation-badge high">üìö 4,856 citations</span>
                            </div>
                            <h3>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</h3>
                            <p class="authors">Yao et al. ‚Ä¢ Princeton + Google DeepMind ‚Ä¢ NeurIPS 2023</p>
                            <p class="idea">Generalizes CoT to tree search. Generate multiple "thoughts," evaluate them, and explore/backtrack. Enables deliberate planning and lookahead that linear CoT cannot achieve.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Key Insight: Reasoning as Search, Not a Path</h4>
                                <p>Chain-of-Thought generates a <strong>single linear path</strong> through the reasoning space. But many problems require exploration‚Äîyou might go down a wrong path and need to backtrack. Tree of Thoughts models reasoning as <strong>search over a tree</strong>, enabling the model to explore multiple branches and back up from dead ends.</p>
                                <div class="key-learning">
                                    <h5>üí° The Breakthrough</h5>
                                    <p>Some problems have no clear solution path until you've tried a few approaches. ToT lets the model say "let me try approach A... that didn't work... let me try approach B" instead of committing to one path. This is how humans solve puzzles.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Four Components of ToT</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Thought Decomposition</div>
                                            <div class="step-desc">Define what a "thought" is for this problem‚Äîa line of code, a sentence, a partial solution, an equation. The granularity matters: too small = too many branches, too large = loses the benefit.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Thought Generator</div>
                                            <div class="step-desc">Generate k candidate next-thoughts from the current state. Either <strong>sample</strong> (generate k different outputs) or <strong>propose</strong> (ask LLM to suggest k options in one call).</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">State Evaluator</div>
                                            <div class="step-desc">Use the LLM to assess how promising each state is: "Can this partial solution lead to success?" Returns a score or categorical rating (sure/maybe/impossible).</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">4</div>
                                        <div class="step-content">
                                            <div class="step-title">Search Algorithm</div>
                                            <div class="step-desc">Use BFS (breadth-first: explore level by level) or DFS (depth-first: go deep then backtrack) to navigate the tree. Which to use depends on the problem structure.</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Example: Game of 24</h4>
                                <div class="example-prompt">
                                    <span class="prompt-label">Problem</span>
Use numbers 4, 5, 6, 10 with +, -, *, / to make 24. Each number used exactly once.

<span class="prompt-label">Tree Search</span>
Root: {4, 5, 6, 10}

Level 1 - Generate operations:
‚îú‚îÄ‚îÄ 10 - 6 = 4 ‚Üí {4, 4, 5}  [Evaluator: "maybe - two 4s could work"]
‚îú‚îÄ‚îÄ 10 - 4 = 6 ‚Üí {5, 6, 6}  [Evaluator: "maybe"]
‚îú‚îÄ‚îÄ 10 + 6 = 16 ‚Üí {4, 5, 16} [Evaluator: "sure - 16 + 4 + 5 - 1 close"]
‚îú‚îÄ‚îÄ 5 * 4 = 20 ‚Üí {6, 10, 20} [Evaluator: "impossible - too big"] ‚úó PRUNE
‚îî‚îÄ‚îÄ ...

Level 2 - Continue from promising nodes:
From {4, 4, 5}:
‚îú‚îÄ‚îÄ 4 + 4 = 8 ‚Üí {5, 8}
‚îÇ   ‚îî‚îÄ‚îÄ 5 * 8 = 40 ‚úó
‚îú‚îÄ‚îÄ 4 * 4 = 16 ‚Üí {5, 16}
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ 5 - 4 = 1 ‚Üí {1, 4}
    ‚îî‚îÄ‚îÄ ... nope, backtrack

Eventually find: (10 - 4) * (6 - 5 + 1)... or another valid path ‚úì</div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Task</th><th>CoT</th><th>ToT (BFS)</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Game of 24</td><td>4.0%</td><td><span class="metric-highlight">74.0%</span></td><td>+70%</td></tr>
                                        <tr><td>Creative Writing</td><td>6.2</td><td><span class="metric-highlight">7.6</span></td><td>+1.4</td></tr>
                                        <tr><td>Mini Crosswords</td><td>15.6%</td><td><span class="metric-highlight">35.4%</span></td><td>+20%</td></tr>
                                    </tbody>
                                </table>
                                <div class="callout-box">
                                    <h5>The Game of 24 Result</h5>
                                    <p>CoT achieves only 4% on Game of 24 because it commits to operations that might be wrong. ToT achieves 74% by exploring multiple operation sequences and backtracking. This is exactly the type of problem where search beats linear reasoning.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>BFS vs DFS: When to Use Which</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Strategy</th><th>How It Works</th><th>Best For</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td><strong>BFS</strong></td><td>Explore all level-n nodes before level-n+1</td><td>When solutions are likely at similar depths</td></tr>
                                        <tr><td><strong>DFS</strong></td><td>Go deep on one path, backtrack if stuck</td><td>When you need to see full solutions to evaluate</td></tr>
                                    </tbody>
                                </table>
                                <p style="margin-top: 12px;"><strong>Game of 24:</strong> Uses BFS because partial equations can be evaluated.<br>
                                <strong>Creative Writing:</strong> Uses DFS because you need full paragraphs to judge coherence.</p>
                            </div>

                            <div class="expanded-section">
                                <h4>The Evaluator Prompt</h4>
                                <div class="code-block">
<span class="comment"># Example evaluator prompt for Game of 24:</span>

Evaluate if given numbers can reach 24 (sure/maybe/impossible).

10 14
10 + 14 = 24
<span class="string">sure</span>

11 12
11 + 12 = 23, 11 * 12 = 132, 12 - 11 = 1, 11 / 12 = 0.91
<span class="string">impossible</span>

4 4 10
4 + 4 + 10 = 18, 4 * 4 - 10 = 6, (10 - 4) * 4 = 24
<span class="string">sure</span>

{input_numbers}
</div>
                            </div>

                            <div class="expanded-section">
                                <h4>When to Use ToT</h4>
                                <ul>
                                    <li><strong>Combinatorial puzzles:</strong> Game of 24, Sudoku, crosswords</li>
                                    <li><strong>Creative generation:</strong> Where multiple paths could work</li>
                                    <li><strong>Planning problems:</strong> Route finding, scheduling</li>
                                    <li><strong>Hard reasoning:</strong> When first attempt likely fails</li>
                                    <li><strong>NOT for:</strong> Simple QA, factual questions, or problems with clear solution paths</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Cost-Benefit Analysis</h4>
                                <ul>
                                    <li><strong>Compute:</strong> 10-100x more LLM calls than single CoT</li>
                                    <li><strong>Latency:</strong> Sequential exploration adds significant time</li>
                                    <li><strong>When worth it:</strong> Hard problems where CoT fails, high-stakes accuracy</li>
                                    <li><strong>When not worth it:</strong> Simple problems, latency-critical, budget-constrained</li>
                                </ul>
                                <div class="key-learning">
                                    <h5>üí° Practical Guidance</h5>
                                    <p>Try CoT first. If it fails consistently on a problem type, consider ToT. For production, use ToT selectively on the hardest queries only‚Äîuse a classifier to decide.</p>
                                </div>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2305.10601" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://github.com/princeton-nlp/tree-of-thought-llm" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                Official GitHub
                            </a>
                            <a href="https://www.promptingguide.ai/techniques/tot" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                                Prompting Guide
                            </a>
                        </div>
                    </div>
                </div>

                <!-- LLM-ToT Paper -->
                <div class="paper-card tree" id="card-llm-tot">
                    <div class="paper-header" onclick="toggleCard('card-llm-tot')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">LLM-Guided ToT</span>
                                <span class="citation-badge">üìö 314 citations</span>
                            </div>
                            <h3>Large Language Model Guided Tree-of-Thought</h3>
                            <p class="authors">Long et al. ‚Ä¢ 2023</p>
                            <p class="idea">Uses an LLM to guide the tree exploration itself, rather than fixed BFS/DFS. The LLM learns which branches to explore, making search more efficient and targeted.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section">
                                <h4>Key Improvements</h4>
                                <ul>
                                    <li>LLM decides which node to expand next</li>
                                    <li>More efficient than blind BFS/DFS</li>
                                    <li>Learns from evaluation history</li>
                                    <li>Adaptive search depth based on problem</li>
                                </ul>
                            </div>
                            <div class="expanded-section">
                                <h4>Core Technique</h4>
                                <p>Instead of fixed search strategy, prompt the LLM with the current tree state and ask: "Which thought should we explore next?" The LLM acts as both the thought generator and the search controller.</p>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2305.08291" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div class="section-header">
                <div class="line-indicator program"></div>
                <h2>Program-Based Line</h2>
            </div>
            <div class="papers-grid">
                <!-- PoT Paper -->
                <div class="paper-card program" id="card-pot">
                    <div class="paper-header" onclick="toggleCard('card-pot')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">PoT</span>
                                <span class="citation-badge high">üìö 1,083 citations</span>
                            </div>
                            <h3>Program of Thoughts Prompting: Disentangling Computation from Reasoning</h3>
                            <p class="authors">Chen et al. ‚Ä¢ CMU + Salesforce ‚Ä¢ 2022</p>
                            <p class="idea">Instead of reasoning in natural language, generate Python code that performs the computation. Execute the code to get the answer. Separates "what to compute" from "how to compute."</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Key Insight: Let the Computer Do the Computing</h4>
                                <p>CoT asks the LLM to both <strong>reason about what to compute</strong> AND <strong>perform the computation</strong>. But LLMs are bad at arithmetic‚Äîthey make mistakes on "what is 37 √ó 89?". PoT separates these: the LLM writes code describing the computation, then Python executes it exactly.</p>
                                <div class="key-learning">
                                    <h5>üí° The Breakthrough</h5>
                                    <p>LLMs are reasoning engines, not calculators. When you ask an LLM "what is 127 √ó 38 + 94?", it's doing pattern matching‚Äîand sometimes gets it wrong. But when you ask "write code to compute this", it generates code and Python gets it exactly right every time.</p>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>CoT vs PoT: Side by Side</h4>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px;">
                                    <div class="example-prompt">
                                        <span class="prompt-label">Chain-of-Thought</span>
Q: Janet pays $40/hour. She works 8 hours on Mon, Tue, Wed, and 6 hours on Thu, Fri. Weekly pay?

A: Mon-Wed: 40 √ó 8 = 320 per day
   Three days: 320 √ó 3 = 960
   Thu-Fri: 40 √ó 6 = 240 per day
   Two days: 240 √ó 2 = 480
   Total: 960 + 480 = 1440

‚ùå Manual math can have errors</div>
                                    <div class="example-prompt">
                                        <span class="prompt-label">Program of Thoughts</span>
hourly = 40
mon_wed = hourly * 8 * 3
thu_fri = hourly * 6 * 2
total = mon_wed + thu_fri
print(total)  # 1440

‚úì Python is always exact</div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Benchmark Results</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Benchmark</th><th>CoT</th><th>PoT</th><th>Gain</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>GSM8K (math)</td><td>58.0%</td><td><span class="metric-highlight">80.0%</span></td><td>+22%</td></tr>
                                        <tr><td>AQuA (algebra)</td><td>35.8%</td><td><span class="metric-highlight">58.0%</span></td><td>+22%</td></tr>
                                        <tr><td>SVAMP (math)</td><td>78.2%</td><td><span class="metric-highlight">88.0%</span></td><td>+10%</td></tr>
                                        <tr><td>TabMWP (tables)</td><td>62.0%</td><td><span class="metric-highlight">76.8%</span></td><td>+15%</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section">
                                <h4>When PoT Excels</h4>
                                <ul>
                                    <li><strong>Multi-step arithmetic:</strong> Compound interest, tax calculations</li>
                                    <li><strong>Iterative problems:</strong> "After N days...", simulation</li>
                                    <li><strong>Table/data operations:</strong> Filtering, aggregating</li>
                                    <li><strong>NOT for:</strong> Commonsense reasoning, strategy problems</li>
                                </ul>
                                <div class="callout-box">
                                    <h5>The Pattern</h5>
                                    <p>Use PoT whenever the answer requires computation that Python can execute. If the answer is a number from calculation, PoT beats CoT.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Limitations</h4>
                                <ul>
                                    <li><strong>Execution needed:</strong> Must run Python safely (sandbox)</li>
                                    <li><strong>Code errors:</strong> Syntax/runtime errors still happen</li>
                                    <li><strong>Logic errors:</strong> Correct math on wrong formula = wrong answer</li>
                                    <li><strong>Non-computational tasks:</strong> Can't help with reasoning-only problems</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2211.12588" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://github.com/wenhuchen/Program-of-Thoughts" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                GitHub
                            </a>
                            <a href="https://arxiv.org/pdf/2211.12588.pdf" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path><polyline points="7 10 12 15 17 10"></polyline><line x1="12" y1="15" x2="12" y2="3"></line></svg>
                                PDF
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div class="section-header">
                <div class="line-indicator survey"></div>
                <h2>2025 Survey Papers: The State of the Art</h2>
            </div>
            <div class="papers-grid">
                <!-- System 1 to System 2 Survey -->
                <div class="paper-card survey" id="card-sys2">
                    <div class="paper-header" onclick="toggleCard('card-sys2')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">System 1‚Üí2</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>From System 1 to System 2: A Survey of Reasoning Large Language Models</h3>
                            <p class="authors">Li et al. ‚Ä¢ Feb 2025</p>
                            <p class="idea">Comprehensive survey covering the transition from "fast thinking" (System 1) to "slow, deliberate reasoning" (System 2) in LLMs. Covers construction methods, benchmarks, and open problems.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Core Framework: System 1 vs System 2</h4>
                                <p>This survey borrows Daniel Kahneman's dual-process theory to explain LLM evolution:</p>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">
                                    <div class="example-prompt">
                                        <span class="prompt-label">System 1 (Fast Thinking)</span>
‚Ä¢ Pattern matching on training data
‚Ä¢ Single forward pass per token
‚Ä¢ "What's 2+2?" ‚Üí "4" (instant)
‚Ä¢ Prone to hallucination on novel tasks
‚Ä¢ GPT-4, Claude 3.5 in standard mode</div>
                                    <div class="example-prompt">
                                        <span class="prompt-label">System 2 (Slow Thinking)</span>
‚Ä¢ Deliberate step-by-step reasoning
‚Ä¢ Many tokens of "thinking" before answer
‚Ä¢ "What's 127√ó38?" ‚Üí [long reasoning] ‚Üí "4826"
‚Ä¢ More accurate on complex reasoning
‚Ä¢ o1, o3, R1, Claude in thinking mode</div>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Progression: How We Got to Reasoning Models</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Prompt Engineering Era (2022)</div>
                                            <div class="step-desc">CoT, Self-Consistency, Least-to-Most. External prompts unlock reasoning without changing the model.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Supervised Fine-Tuning (2023)</div>
                                            <div class="step-desc">Train on reasoning traces. Models learn to generate CoT by default without prompting.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Reinforcement Learning (2024)</div>
                                            <div class="step-desc">RL from outcome feedback. o1 and R1 learn to reason through trial-and-error, not just imitation.</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">4</div>
                                        <div class="step-content">
                                            <div class="step-title">Test-Time Scaling (2024-25)</div>
                                            <div class="step-desc">More thinking tokens at inference = better answers. Trading compute for capability.</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Key Insight for Practitioners</h4>
                                <div class="key-learning">
                                    <h5>üí° The Trade-off</h5>
                                    <p>System 2 reasoning costs 10-100x more tokens but solves problems System 1 cannot. The skill is knowing <em>when</em> to use each‚Äîdon't pay System 2 costs for System 1 problems.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Survey Coverage</h4>
                                <ul>
                                    <li>150+ papers systematically reviewed</li>
                                    <li>Construction methods: prompting ‚Üí SFT ‚Üí RL ‚Üí hybrid</li>
                                    <li>Benchmarks: GSM8K, MATH, ARC, coding tasks</li>
                                    <li>Open problems: efficiency, verification, generalization</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2502.17419" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                            <a href="https://github.com/zzli2022/Awesome-Slow-Reason-System" target="_blank" class="paper-link">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                Awesome List (Updated)
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Large Reasoning Models Survey -->
                <div class="paper-card survey" id="card-lrm">
                    <div class="paper-header" onclick="toggleCard('card-lrm')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">LRM Survey</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>Towards Large Reasoning Models: A Survey of Reinforced Test-Time Scaling</h3>
                            <p class="authors">Xu et al. ‚Ä¢ Jan 2025</p>
                            <p class="idea">Focuses on the transition from LLMs to "Large Reasoning Models" through test-time scaling. Covers o1-style long CoT, automated data construction, and RL-based learning-to-reason.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The New Paradigm: LLM ‚Üí LRM</h4>
                                <p>This survey defines the transition from Large Language Models to <strong>Large Reasoning Models</strong>‚Äîmodels specifically trained to "think" before answering:</p>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Aspect</th><th>LLM (GPT-4, Claude)</th><th>LRM (o1, R1)</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Output style</td><td>Direct answer</td><td>Thinking trace ‚Üí answer</td></tr>
                                        <tr><td>Tokens per response</td><td>100s-1000s</td><td>10,000s-100,000s</td></tr>
                                        <tr><td>Training</td><td>Next-token prediction</td><td>RL on reasoning outcomes</td></tr>
                                        <tr><td>Scaling axis</td><td>Parameters (train-time)</td><td>Thinking tokens (test-time)</td></tr>
                                        <tr><td>Best for</td><td>Creative, conversational</td><td>Math, logic, coding</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Test-Time Scaling Revolution</h4>
                                <p>Traditional scaling: "Bigger model = better results" (train-time compute). The LRM insight:</p>
                                <div class="key-learning">
                                    <h5>üí° Test-Time Scaling</h5>
                                    <p><strong>More thinking tokens at inference = better reasoning</strong>, even with the same model. o1 can "think longer" on hard problems. This shifts the cost from training to inference‚Äîyou pay per query, not per model.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>How LRMs Are Built</h4>
                                <div class="step-by-step">
                                    <div class="step">
                                        <div class="step-number">1</div>
                                        <div class="step-content">
                                            <div class="step-title">Data: Long CoT traces</div>
                                            <div class="step-desc">Generate or curate reasoning traces with verification steps</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">2</div>
                                        <div class="step-content">
                                            <div class="step-title">Training: RL from outcomes</div>
                                            <div class="step-desc">Reward correct final answers, let model discover good reasoning</div>
                                        </div>
                                    </div>
                                    <div class="step">
                                        <div class="step-number">3</div>
                                        <div class="step-content">
                                            <div class="step-title">Inference: Variable compute</div>
                                            <div class="step-desc">Harder problems get more thinking tokens automatically</div>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Practical Implications</h4>
                                <ul>
                                    <li><strong>Cost model changes:</strong> Pay per reasoning step, not just per token</li>
                                    <li><strong>Latency increases:</strong> Expect 10-60 seconds for complex reasoning</li>
                                    <li><strong>When to use:</strong> Math, coding, logic puzzles‚ÄîNOT chat or creativity</li>
                                    <li><strong>DIY option:</strong> Fine-tune on reasoning traces + RL (see DeepSeek R1)</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2501.09686" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Efficient Reasoning Survey -->
                <div class="paper-card survey" id="card-efficient">
                    <div class="paper-header" onclick="toggleCard('card-efficient')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Efficiency</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>Efficient Reasoning Models: A Survey</h3>
                            <p class="authors">Feng et al. ‚Ä¢ Apr 2025</p>
                            <p class="idea">Addresses the efficiency crisis in reasoning models. Organizes solutions into three axes: Shorter (compressed CoT), Smaller (distilled models), Faster (accelerated decoding).</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Efficiency Crisis</h4>
                                <p>Reasoning models achieve breakthrough accuracy but at extreme cost:</p>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Metric</th><th>Standard LLM</th><th>Reasoning Model (o1)</th><th>Impact</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td>Tokens per query</td><td>~500</td><td>~50,000+</td><td>100x cost</td></tr>
                                        <tr><td>Latency</td><td>1-3 seconds</td><td>30-120 seconds</td><td>UX impact</td></tr>
                                        <tr><td>Cost per query</td><td>$0.001-0.01</td><td>$0.10-1.00</td><td>$$ scaling</td></tr>
                                        <tr><td>GPU memory</td><td>Moderate</td><td>Long context needed</td><td>Infra cost</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Three Efficiency Axes</h4>
                                <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px;">
                                    <div class="example-prompt" style="padding: 16px;">
                                        <span class="prompt-label">üìè SHORTER</span>
<strong>Compress reasoning length</strong>

‚Ä¢ Concise CoT training
‚Ä¢ Reasoning distillation
‚Ä¢ Skip unnecessary steps
‚Ä¢ "Say less, reason better"

Goal: Same accuracy, fewer tokens</div>
                                    <div class="example-prompt" style="padding: 16px;">
                                        <span class="prompt-label">üì¶ SMALLER</span>
<strong>Smaller model, same capability</strong>

‚Ä¢ Knowledge distillation
‚Ä¢ Reasoning transfer learning
‚Ä¢ Model compression + RL
‚Ä¢ 7B matching 70B

Goal: Commodity GPU deployment</div>
                                    <div class="example-prompt" style="padding: 16px;">
                                        <span class="prompt-label">‚ö° FASTER</span>
<strong>Accelerate inference</strong>

‚Ä¢ Speculative decoding
‚Ä¢ Parallel reasoning paths
‚Ä¢ Early exit strategies
‚Ä¢ KV cache optimization

Goal: Real-time reasoning</div>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Key Techniques</h4>
                                <ul>
                                    <li><strong>Distillation:</strong> Train small model on big model's reasoning traces (DeepSeek-R1-Distill)</li>
                                    <li><strong>Adaptive compute:</strong> Easy problems ‚Üí short thinking; Hard ‚Üí long thinking</li>
                                    <li><strong>Compressed CoT:</strong> Train to reason in fewer tokens without accuracy loss</li>
                                    <li><strong>Speculative decoding:</strong> Draft tokens with small model, verify with large</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Practical Takeaway</h4>
                                <div class="key-learning">
                                    <h5>üí° The 10x Rule</h5>
                                    <p>For production deployment, you need reasoning efficiency to improve 10x from current state-of-art. Watch distillation research closely‚Äî7B distilled models are already matching 70B on many benchmarks.</p>
                                </div>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2504.10903" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Logical Reasoning Survey -->
                <div class="paper-card survey" id="card-logical">
                    <div class="paper-header" onclick="toggleCard('card-logical')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Logical</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>Logical Reasoning in Large Language Models: A Survey</h3>
                            <p class="authors">Liu et al. ‚Ä¢ Feb 2025</p>
                            <p class="idea">Deep dive into formal logical reasoning: deductive, inductive, abductive, and analogical. Covers neuro-symbolic methods, RL approaches, and why LLMs still struggle with rigorous logic.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Four Types of Logical Reasoning</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Type</th><th>Direction</th><th>Example</th><th>LLM Performance</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td><strong>Deductive</strong></td><td>General ‚Üí Specific</td><td>"All humans are mortal. Socrates is human. ‚à¥ Socrates is mortal."</td><td>Good with simple chains, fails on complex</td></tr>
                                        <tr><td><strong>Inductive</strong></td><td>Specific ‚Üí General</td><td>"Swan 1 is white, Swan 2 is white... ‚à¥ All swans are white"</td><td>Prone to overgeneralization</td></tr>
                                        <tr><td><strong>Abductive</strong></td><td>Effect ‚Üí Best Cause</td><td>"The grass is wet. Best explanation: It rained."</td><td>Reasonable but not rigorous</td></tr>
                                        <tr><td><strong>Analogical</strong></td><td>Domain A ‚Üí Domain B</td><td>"Atom is like solar system: nucleus = sun, electrons = planets"</td><td>Creative but often superficial</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>Why LLMs Struggle with Formal Logic</h4>
                                <div class="key-learning">
                                    <h5>üí° The Core Problem</h5>
                                    <p>LLMs do <strong>soft pattern matching</strong>, not <strong>hard symbolic manipulation</strong>. They've seen "Socrates is mortal" in training data, so they pattern-match to the right answer‚Äîbut they can't reliably apply modus ponens to novel entities. The survey shows LLMs fail on negation ("not"), quantifiers ("all", "some"), and multi-hop reasoning.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Enhancement Approaches</h4>
                                <ul>
                                    <li><strong>Data-centric:</strong> Fine-tune on formal logic datasets (ProofWriter, FOLIO)</li>
                                    <li><strong>Neuro-symbolic:</strong> LLM generates logical forms ‚Üí external solver executes</li>
                                    <li><strong>RL for logic:</strong> Reward valid inference chains</li>
                                    <li><strong>Constrained decoding:</strong> Force outputs to follow logical grammar</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Practical Implications</h4>
                                <ul>
                                    <li><strong>Don't trust LLMs for formal proofs</strong> without verification</li>
                                    <li><strong>Use hybrid systems</strong> for logic-critical applications</li>
                                    <li><strong>Test edge cases:</strong> Negation, quantifier scope, contradiction</li>
                                    <li><strong>Best results:</strong> LLM proposes, symbolic system verifies</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2502.09100" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Trustworthy Reasoning Survey -->
                <div class="paper-card survey" id="card-trust">
                    <div class="paper-header" onclick="toggleCard('card-trust')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Trustworthy</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>A Comprehensive Survey on Trustworthiness in Reasoning Models and Chain-of-Thought</h3>
                            <p class="authors">Wang et al. ‚Ä¢ 2025</p>
                            <p class="idea">Examines reasoning through the lens of trustworthiness: truthfulness, safety, robustness, fairness, and privacy. Critical for deploying reasoning systems in production.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Five Pillars of Trustworthy Reasoning</h4>
                                <table class="comparison-table">
                                    <thead>
                                        <tr><th>Pillar</th><th>Definition</th><th>Failure Example</th><th>Mitigation</th></tr>
                                    </thead>
                                    <tbody>
                                        <tr><td><strong>Truthfulness</strong></td><td>Reasoning reflects reality</td><td>Confident but wrong math steps</td><td>Self-consistency, verification</td></tr>
                                        <tr><td><strong>Safety</strong></td><td>No harmful outputs</td><td>Reasoning toward dangerous instructions</td><td>Output filtering, RLHF</td></tr>
                                        <tr><td><strong>Robustness</strong></td><td>Works under attack</td><td>Jailbreaks via reasoning injection</td><td>Adversarial training</td></tr>
                                        <tr><td><strong>Fairness</strong></td><td>Unbiased reasoning</td><td>Different conclusions for similar cases</td><td>Debiasing, auditing</td></tr>
                                        <tr><td><strong>Privacy</strong></td><td>No data leakage</td><td>Reasoning reveals training examples</td><td>Differential privacy</td></tr>
                                    </tbody>
                                </table>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Amplification Problem</h4>
                                <div class="key-learning">
                                    <h5>üí° Why Long Reasoning is Riskier</h5>
                                    <p>Extended reasoning (o1-style) amplifies <em>both</em> capabilities and risks. Each reasoning step is an opportunity for: (1) accumulating errors, (2) introducing biases, (3) generating unsafe content, (4) leaking private information. A 100-step reasoning chain has 100x the attack surface of a direct answer.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Key Findings</h4>
                                <ul>
                                    <li><strong>Faithfulness gap:</strong> CoT often doesn't reflect actual model computation</li>
                                    <li><strong>Sycophancy risk:</strong> Reasoning can be steered by user preferences</li>
                                    <li><strong>Jailbreak vectors:</strong> Reasoning steps can be exploited for attacks</li>
                                    <li><strong>Consistency issues:</strong> Same problem, different reasoning, different answers</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Production Checklist</h4>
                                <ul>
                                    <li>‚úì Verify reasoning chains independently of final answer</li>
                                    <li>‚úì Monitor for reasoning drift over conversation</li>
                                    <li>‚úì Test with adversarial inputs before deployment</li>
                                    <li>‚úì Audit for demographic bias in reasoning paths</li>
                                    <li>‚úì Implement early termination for suspicious reasoning</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2509.03871" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Implicit Reasoning Survey -->
                <div class="paper-card survey" id="card-implicit">
                    <div class="paper-header" onclick="toggleCard('card-implicit')">
                        <div class="paper-header-content">
                            <div class="paper-meta-badges">
                                <span class="station-badge">Implicit</span>
                                <span class="citation-badge">üìö 2025 Survey</span>
                            </div>
                            <h3>Implicit Reasoning in Large Language Models</h3>
                            <p class="authors">Li et al. ‚Ä¢ 2025</p>
                            <p class="idea">Can models reason without generating explicit CoT? This survey explores "implicit reasoning" via latent structures, trading off interpretability for efficiency.</p>
                        </div>
                        <div class="expand-icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="6 9 12 15 18 9"></polyline>
                            </svg>
                        </div>
                    </div>
                    <div class="paper-expanded">
                        <div class="expanded-grid">
                            <div class="expanded-section full-width-section">
                                <h4>The Core Trade-off: Explicit vs Implicit Reasoning</h4>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px;">
                                    <div class="example-prompt">
                                        <span class="prompt-label">Explicit Reasoning (CoT)</span>
<strong>Reasoning visible in output tokens</strong>

Q: What is 23 √ó 17?
A: Let me think step by step...
   23 √ó 17 = 23 √ó (10 + 7)
   = 230 + 161
   = 391

‚úì Interpretable, debuggable
‚úó Slow (100s-1000s tokens)
‚úó Expensive ($$$)</div>
                                    <div class="example-prompt">
                                        <span class="prompt-label">Implicit Reasoning</span>
<strong>Reasoning in hidden states</strong>

Q: What is 23 √ó 17?
A: 391

(Reasoning happened in the
neural network activations,
not visible to users)

‚úì Fast (minimal tokens)
‚úì Cheap
‚úó Opaque, unverifiable
‚úó Hard to debug failures</div>
                                </div>
                            </div>

                            <div class="expanded-section full-width-section">
                                <h4>The Research Frontier</h4>
                                <div class="key-learning">
                                    <h5>üí° The Best of Both Worlds?</h5>
                                    <p>Can we train models that reason implicitly (fast, cheap) but achieve explicit reasoning accuracy? Early research shows promise: "pause tokens" let models think without visible output, latent reasoning heads show computation happening in hidden states. The goal: o1-level reasoning at GPT-4 speed.</p>
                                </div>
                            </div>

                            <div class="expanded-section">
                                <h4>Approaches Surveyed</h4>
                                <ul>
                                    <li><strong>Pause tokens:</strong> Special tokens that give model "thinking time" without output</li>
                                    <li><strong>Latent reasoning:</strong> Train hidden states to perform computation</li>
                                    <li><strong>Compressed CoT:</strong> Distill long reasoning into internal representations</li>
                                    <li><strong>Recurrent depth:</strong> Loop through layers multiple times for harder problems</li>
                                </ul>
                            </div>

                            <div class="expanded-section">
                                <h4>Why This Matters</h4>
                                <ul>
                                    <li><strong>Cost:</strong> Implicit reasoning could reduce inference cost 100x</li>
                                    <li><strong>Latency:</strong> Real-time reasoning applications become possible</li>
                                    <li><strong>Verification challenge:</strong> How do you trust reasoning you can't see?</li>
                                    <li><strong>Human parallel:</strong> We don't verbalize every thought‚Äîmaybe AI shouldn't either</li>
                                </ul>
                            </div>
                        </div>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2509.02350" target="_blank" class="paper-link primary">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline></svg>
                                arXiv Paper
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Footer -->
        <footer class="footer">
            <p>Part of <a href="../index.html">Maxpool</a> ‚Ä¢ Production AI Engineering Resources</p>
            <p style="margin-top: 8px;"><a href="https://join.maxpool.dev" target="_blank">Join the Community ‚Üí</a></p>
        </footer>
    </div>

    <!-- Tooltip -->
    <div class="tooltip" id="tooltip">
        <div class="tooltip-title"></div>
        <div class="tooltip-authors"></div>
        <div class="tooltip-idea"></div>
        <div class="tooltip-citations"></div>
    </div>

    <script>
        // Toggle card expansion
        function toggleCard(cardId) {
            const card = document.getElementById(cardId);
            card.classList.toggle('expanded');
        }

        // Paper data for tooltips
        const papers = {
            'cot': {
                title: 'Chain-of-Thought Prompting',
                authors: 'Wei et al., 2022',
                idea: 'Adding step-by-step reasoning examples dramatically boosts performance on reasoning benchmarks.',
                citations: '17,700+ citations'
            },
            'self-consistency': {
                title: 'Self-Consistency',
                authors: 'Wang et al., 2022',
                idea: 'Sample many reasoning paths and pick the most common answer. Ensemble-style decoding.',
                citations: '4,200+ citations'
            },
            'least-to-most': {
                title: 'Least-to-Most Prompting',
                authors: 'Zhou et al., 2022',
                idea: 'Decompose problems into subproblems, solve from easiest to hardest.',
                citations: '1,400+ citations'
            },
            'cot-no-prompt': {
                title: 'CoT Without Prompting',
                authors: 'Wang & Zhou, 2024',
                idea: 'CoT emerges in alternative decoding paths without explicit prompts.',
                citations: '168 citations'
            },
            'react': {
                title: 'ReAct',
                authors: 'Yao et al., 2022',
                idea: 'Interleave reasoning with actions. Foundation of modern AI agents.',
                citations: '5,886 citations'
            },
            'reflexion': {
                title: 'Reflexion',
                authors: 'Shinn et al., 2023',
                idea: 'Self-reflection in natural language for improvement without weight updates.',
                citations: '2,855 citations'
            },
            'tot': {
                title: 'Tree of Thoughts',
                authors: 'Yao et al., 2023',
                idea: 'Tree search over thoughts with exploration and backtracking.',
                citations: '4,856 citations'
            },
            'llm-tot': {
                title: 'LLM-Guided ToT',
                authors: 'Long et al., 2023',
                idea: 'Use LLM to guide tree exploration for better search policy.',
                citations: '314 citations'
            },
            'pot': {
                title: 'Program of Thoughts',
                authors: 'Chen et al., 2022',
                idea: 'Generate executable code to separate computation from reasoning.',
                citations: '1,083 citations'
            },
            'sys2-survey': {
                title: 'From System 1 to System 2: A Survey of Reasoning LLMs',
                authors: 'Sun et al., 2025',
                idea: 'Comprehensive survey of the transition from fast pattern-matching (System 1) to slow deliberate reasoning (System 2) in LLMs.',
                citations: '2025 Survey'
            },
            'lrm-survey': {
                title: 'Large Reasoning Models Survey',
                authors: 'Various, 2025',
                idea: 'Survey of Large Reasoning Models (LRMs) like o1, o3, R1 that use extended chain-of-thought with verification.',
                citations: '2025 Survey'
            },
            'efficient-survey': {
                title: 'Efficient Reasoning Survey',
                authors: 'Various, 2025',
                idea: 'Survey of techniques to make reasoning more efficient: shorter chains, adaptive compute, distillation.',
                citations: '2025 Survey'
            }
        };

        // Tooltip functionality
        const tooltip = document.getElementById('tooltip');
        const stations = document.querySelectorAll('.station');

        stations.forEach(station => {
            station.addEventListener('mouseenter', (e) => {
                const paperId = station.dataset.paper;
                const paper = papers[paperId];

                if (paper) {
                    tooltip.querySelector('.tooltip-title').textContent = paper.title;
                    tooltip.querySelector('.tooltip-authors').textContent = paper.authors;
                    tooltip.querySelector('.tooltip-idea').textContent = paper.idea;
                    tooltip.querySelector('.tooltip-citations').textContent = paper.citations;

                    tooltip.classList.add('visible');
                }
            });

            station.addEventListener('mousemove', (e) => {
                tooltip.style.left = e.clientX + 15 + 'px';
                tooltip.style.top = e.clientY + 15 + 'px';
            });

            station.addEventListener('mouseleave', () => {
                tooltip.classList.remove('visible');
            });
        });
    </script>
</body>
</html>
