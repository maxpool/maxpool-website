<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Reliability Timeline: Half-Life Analysis & Long Task Completion</title>
    <style>
        @page {
            margin: 2cm;
        }
        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: white;
        }
        h1 {
            color: #1a1a1a;
            font-size: 28px;
            margin-bottom: 10px;
            text-align: center;
            border-bottom: 2px solid #DC8850;
            padding-bottom: 15px;
        }
        h2 {
            color: #DC8850;
            font-size: 22px;
            margin-top: 35px;
            margin-bottom: 15px;
            border-bottom: 1px solid #e0e0e0;
            padding-bottom: 8px;
        }
        h3 {
            color: #555;
            font-size: 18px;
            margin-top: 25px;
            margin-bottom: 12px;
            font-weight: 600;
        }
        .authors {
            text-align: center;
            font-style: italic;
            margin-bottom: 30px;
            color: #666;
        }
        .abstract {
            background: #f8f8f8;
            padding: 20px;
            border-left: 4px solid #DC8850;
            margin: 20px 0;
        }
        .key-finding {
            background: #fff8f0;
            padding: 15px;
            border-left: 4px solid #DC8850;
            margin: 20px 0;
        }
        .key-finding h3 {
            margin-top: 0;
            color: #DC8850;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #DC8850;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .metric {
            font-weight: bold;
            color: #DC8850;
        }
        .performance-improvement {
            color: #27ae60;
            font-weight: bold;
        }
        .performance-decline {
            color: #e74c3c;
            font-weight: bold;
        }
        ul, ol {
            margin: 15px 0;
            padding-left: 30px;
        }
        li {
            margin: 8px 0;
        }
        .methodology-box {
            background: #f0f8ff;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .conclusion-box {
            background: #f0f0f0;
            padding: 20px;
            border-radius: 5px;
            margin-top: 30px;
        }
        .badge {
            display: inline-block;
            padding: 4px 10px;
            background: #DC8850;
            color: white;
            border-radius: 3px;
            font-size: 12px;
            font-weight: bold;
            margin-right: 8px;
        }
        .badge-success {
            background: #27ae60;
        }
        .badge-warning {
            background: #f39c12;
        }
        .badge-danger {
            background: #e74c3c;
        }
        .formula {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            text-align: center;
            margin: 20px 0;
            overflow-x: auto;
        }
        .eli5-box {
            background: #e8f5e9;
            padding: 20px;
            border-left: 4px solid #4caf50;
            margin: 20px 0;
            font-size: 15px;
        }
        .eli5-box h3 {
            margin-top: 0;
            color: #4caf50;
        }
        .figure {
            margin: 30px 0;
            text-align: center;
        }
        .figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid #e0e0e0;
            border-radius: 5px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .figure-caption {
            font-style: italic;
            color: #666;
            margin-top: 10px;
            font-size: 14px;
        }
        .timeline-box {
            background: linear-gradient(to right, #f8f8f8, #fff);
            padding: 20px;
            border-left: 4px solid #DC8850;
            margin: 20px 0;
            position: relative;
        }
        .timeline-item {
            margin: 15px 0;
            padding-left: 30px;
            position: relative;
        }
        .timeline-item:before {
            content: "‚Ä¢";
            position: absolute;
            left: 10px;
            color: #DC8850;
            font-size: 20px;
        }
        .timeline-date {
            font-weight: bold;
            color: #DC8850;
        }
        .insight-box {
            background: #fffbf0;
            border: 2px solid #DC8850;
            border-radius: 8px;
            padding: 20px;
            margin: 25px 0;
        }
        .insight-box h3 {
            color: #DC8850;
            margin-top: 0;
        }
        .source-box {
            background: #f0f0f0;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .source-box a {
            color: #DC8850;
            text-decoration: none;
            font-weight: bold;
        }
        .source-box a:hover {
            text-decoration: underline;
        }
        .navigation {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background: #f8f8f8;
            border-radius: 5px;
        }
        .navigation a {
            color: #DC8850;
            text-decoration: none;
            margin: 0 15px;
            font-weight: bold;
        }
        .navigation a:hover {
            text-decoration: underline;
        }
        p {
            margin: 15px 0;
            text-align: justify;
        }
    </style>
</head>
<body>
    <div class="navigation">
        <a href="../index.html">‚Üê Home</a>
        <a href="../agent/index.html">Agent Reliability</a>
        <a href="../rag/index.html">RAG Patterns</a>
        <a href="../research-papers/index.html">Research Papers</a>
        <a href="https://join.maxpool.dev" target="_blank">Join Community ‚Üí</a>
    </div>

    <h1>When Will AI Become Reliable?<br>Half-Life Analysis Meets Exponential Growth</h1>

    <div class="authors">
        Synthesis of research from Toby Ord (Oxford) and METR (Model Evaluation & Threat Research)<br>
        <em>January 2025</em>
    </div>

    <div class="abstract">
        <h2>Executive Summary</h2>
        <p>This analysis synthesizes two groundbreaking research papers to answer a critical question: when will AI agents become reliable enough for real-world deployment? By combining Toby Ord's half-life framework with METR's exponential growth analysis, we can now predict specific reliability thresholds for AI automation.</p>

        <p>The key insight is that AI agents currently fail at a constant rate per unit time (following a half-life model similar to radioactive decay), but this failure rate is improving exponentially‚Äîdoubling in capability every 7 months. This creates predictable thresholds: current models (2025) can handle 50-minute tasks at 50% reliability, but achieving 90% reliability requires limiting tasks to just 7 minutes. By 2030, we project AI will handle month-long tasks, fundamentally transforming software development and business operations.</p>
    </div>

    <div class="eli5-box">
        <h3>üéØ ELI5: The Core Concept</h3>
        <p>Imagine AI agents are like runners who get exponentially more tired as they run. Right now, they can run for about 50 minutes before having a 50% chance of collapsing. But here's the catch: to have a 90% chance of finishing, they can only run for 7 minutes. The good news? Every 7 months, AI agents can run twice as far before getting tired. So what takes 50 minutes today at 50% success will take 100 minutes in 7 months, 200 minutes in 14 months, and so on.</p>
    </div>

    <h2>Part 1: The Half-Life Framework</h2>

    <p>Toby Ord's analysis introduces a powerful conceptual framework: AI agent performance follows survival analysis patterns similar to radioactive decay. Just as radioactive atoms have a constant probability of decay per unit time, AI agents have a constant probability of failure per minute of operation.</p>

    <div class="figure">
        <img src="https://images.squarespace-cdn.com/content/v1/562652dbe4b05bbfdc596fd7/3ac5cc96-1407-48a0-80e4-ab8a226e3d6c/Figure+1.png" alt="METR results on task length">
        <div class="figure-caption">Figure 1: METR's results showing exponential growth in the length of tasks AI agents can reliably complete. Every 7 months, frontier AI agents can solve tasks approximately twice as long.</div>
    </div>

    <h3>The Mathematics of Failure</h3>

    <p>The half-life model reveals that AI systems experience what Ord calls a "constant hazard rate"‚Äîeach minute of operation carries the same probability of failure, regardless of how long the agent has been running. This creates an exponential decay curve for success probability:</p>

    <div class="formula">
        P(success) = e^(-Œªt)<br>
        where Œª = ln(2) / half_life<br>
        and t = task duration
    </div>

    <p>This mathematical relationship has profound implications for reliability engineering. It means that small increases in task duration lead to dramatic decreases in reliability. More importantly, it provides a quantitative framework for understanding exactly how much we need to reduce task duration to achieve target reliability levels.</p>

    <div class="key-finding">
        <h3>Critical Reliability Thresholds</h3>
        <p>The exponential decay model reveals sharp reliability cliffs that every AI engineer must understand:</p>
        <ul>
            <li><strong>80% reliability:</strong> Requires task duration of only 1/3 the half-life</li>
            <li><strong>90% reliability:</strong> Requires task duration of only 1/7 the half-life</li>
            <li><strong>99% reliability:</strong> Requires task duration of only 1/70 the half-life</li>
            <li><strong>99.9% reliability:</strong> Requires task duration of only 1/700 the half-life</li>
        </ul>
        <p>This explains why AI agents that seem "almost there" for long tasks still fail catastrophically‚Äîthe difference between 50% and 90% success isn't linear, it's exponential.</p>
    </div>

    <h3>Why AI Lacks Error Recovery</h3>

    <p>The constant hazard rate suggests current AI systems fundamentally lack error recovery mechanisms. Unlike humans who can recognize mistakes and backtrack, AI agents compound errors forward. Once an agent makes a mistake, it rarely recovers‚Äîeach subsequent action builds on the flawed foundation. This is why breaking tasks into smaller, independently verifiable chunks is so critical for current systems.</p>

    <div class="figure">
        <img src="https://images.squarespace-cdn.com/content/v1/562652dbe4b05bbfdc596fd7/0eed5814-5ddb-49a9-9ed1-2052bcc794f4/Figure+2.png" alt="Test suite composition">
        <div class="figure-caption">Figure 2: Test suite composition across different benchmarks, showing the distribution of software engineering, cybersecurity, reasoning, and ML tasks organized by human completion time.</div>
    </div>

    <h2>Part 2: METR's Exponential Growth Analysis</h2>

    <p>While Ord's half-life model explains why AI fails, METR's comprehensive study of 13 frontier models from 2019-2025 reveals how fast this is improving. Their research introduces a critical metric: the "50% task-completion time horizon"‚Äîthe duration of tasks (measured in human time) that AI can complete with 50% reliability.</p>

    <div class="figure">
        <img src="https://arxiv.org/html/2503.14499v2/x2.png" alt="METR Methodology">
        <div class="figure-caption">Figure 3: METR's three-step methodology for measuring AI agent time horizons, from task creation through human/AI evaluation to statistical modeling.</div>
    </div>

    <h3>The Seven-Month Doubling Time</h3>

    <p>METR's analysis reveals remarkably consistent exponential growth: the 50% time horizon has doubled approximately every 7 months for the past 6 years. This isn't just incremental improvement‚Äîit's compound growth that fundamentally changes what's possible:</p>

    <div class="timeline-box">
        <h3>AI Capability Timeline</h3>
        <div class="timeline-item">
            <span class="timeline-date">2019:</span> ~3 minutes (Early GPT models, basic interactions)
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2021:</span> ~12 minutes (GPT-3, short coding tasks)
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2023:</span> ~25 minutes (ChatGPT/Claude, moderate complexity)
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2025 (Current):</span> ~50 minutes (Claude 3.7 Sonnet, complex tasks)
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2027 (Projected):</span> ~3.5 hours (Half-day automation)
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2030 (Projected):</span> ~1 month (Project-level automation)
        </div>
    </div>

    <h3>What's Driving the Improvements?</h3>

    <p>METR's qualitative analysis identifies three key drivers of capability improvement:</p>

    <div class="methodology-box">
        <h3>Capability Drivers</h3>
        <ol>
            <li><strong>Enhanced Logical Reasoning:</strong> Better chain-of-thought processing, multi-step planning, and problem decomposition abilities</li>
            <li><strong>Improved Tool Utilization:</strong> More sophisticated use of APIs, code execution environments, and external resources</li>
            <li><strong>Greater Reliability:</strong> Better adaptation to unexpected outputs and self-correction mechanisms (though still limited)</li>
        </ol>
    </div>

    <p>Interestingly, the improvements aren't coming from longer context windows or more parameters alone‚Äîthey're emerging from better reasoning architectures and training methodologies. This suggests the trend may continue even as we approach scaling limits.</p>

    <h2>Part 3: Synthesis - Predicting Reliability Thresholds</h2>

    <p>By combining both frameworks, we can now predict when specific use cases become viable. The key insight is that while the half-life (50% success duration) is growing exponentially, the reliability requirements for different applications create distinct adoption thresholds.</p>

    <div class="insight-box">
        <h3>The Unified Model</h3>
        <p>Combining both frameworks gives us a powerful predictive model:</p>
        <div class="formula">
            Task_Duration(year) = 50min √ó 2^((year-2025)√ó12/7)<br>
            Reliability(duration, year) = e^(-duration / Task_Duration(year))
        </div>
        <p>This allows us to calculate exactly when any given task at any reliability threshold becomes feasible.</p>
    </div>

    <h3>Reliability Projections by Use Case</h3>

    <table>
        <thead>
            <tr>
                <th>Use Case</th>
                <th>Required Reliability</th>
                <th>Max Task Duration</th>
                <th>Viable Date</th>
                <th>Status</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Code Review Assistant</td>
                <td>80%</td>
                <td>15 minutes</td>
                <td>Now</td>
                <td><span class="badge badge-success">Ready</span></td>
            </tr>
            <tr>
                <td>Bug Fix Automation</td>
                <td>90%</td>
                <td>7 minutes</td>
                <td>Now</td>
                <td><span class="badge badge-success">Ready</span></td>
            </tr>
            <tr>
                <td>Test Generation</td>
                <td>85%</td>
                <td>10 minutes</td>
                <td>Now</td>
                <td><span class="badge badge-success">Ready</span></td>
            </tr>
            <tr>
                <td>Feature Implementation</td>
                <td>80%</td>
                <td>2 hours</td>
                <td>2026</td>
                <td><span class="badge badge-warning">Soon</span></td>
            </tr>
            <tr>
                <td>Full Sprint Automation</td>
                <td>90%</td>
                <td>1 day</td>
                <td>2028</td>
                <td><span class="badge badge-danger">Future</span></td>
            </tr>
            <tr>
                <td>Project Management</td>
                <td>99%</td>
                <td>1 week</td>
                <td>2030+</td>
                <td><span class="badge badge-danger">Future</span></td>
            </tr>
        </tbody>
    </table>

    <h3>The Reliability Cliff Phenomenon</h3>

    <p>The exponential nature of both curves creates what we call "reliability cliffs"‚Äîsharp transitions where tasks go from impossible to trivial. A task that's completely infeasible today might become 90% reliable just 14 months later. This creates unique challenges for organizations trying to plan their AI adoption strategies.</p>

    <p>Consider a 4-hour task that currently has near-zero success rate. By 2027, when the 50% horizon reaches 3.5 hours, this task will suddenly achieve ~40% success. Just 7 months later, it will reach 67% success. This rapid transition from "impossible" to "reliable" will happen across thousands of business processes simultaneously.</p>

    <h2>Part 4: Practical Engineering Implications</h2>

    <h3>The Seven-Minute Rule</h3>

    <div class="key-finding">
        <h3>Current Best Practice (2025)</h3>
        <p>For 90% reliability with current frontier models, decompose all tasks into subtasks that can complete in under 7 minutes. This is the fundamental constraint that should guide all production AI system design today.</p>
    </div>

    <p>This constraint has profound implications for system architecture. Rather than giving an AI agent a complex task like "implement a new feature," successful systems break this into discrete, verifiable subtasks: "analyze requirements" (5 min), "design data model" (5 min), "implement model class" (7 min), "write unit tests" (5 min), etc.</p>

    <h3>Architecture Patterns for Current Reliability</h3>

    <table>
        <thead>
            <tr>
                <th>Pattern</th>
                <th>Description</th>
                <th>Reliability Improvement</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Task Decomposition</strong></td>
                <td>Break into <5 minute subtasks</td>
                <td>2-3√ó improvement</td>
                <td>All complex tasks</td>
            </tr>
            <tr>
                <td><strong>Parallel Ensemble</strong></td>
                <td>Run 3 agents, take majority vote</td>
                <td>90% ‚Üí 97%</td>
                <td>Critical decisions</td>
            </tr>
            <tr>
                <td><strong>Human Checkpoints</strong></td>
                <td>Review every 15-30 minutes</td>
                <td>Catches cascade failures</td>
                <td>Long-running tasks</td>
            </tr>
            <tr>
                <td><strong>State Verification</strong></td>
                <td>Test after each subtask</td>
                <td>Early error detection</td>
                <td>Stateful operations</td>
            </tr>
            <tr>
                <td><strong>Rollback Capability</strong></td>
                <td>Checkpoint before changes</td>
                <td>Recovery from failures</td>
                <td>Production systems</td>
            </tr>
        </tbody>
    </table>

    <h3>Common Anti-Patterns to Avoid</h3>

    <p>Understanding the half-life model helps identify several anti-patterns that doom AI projects to failure:</p>

    <ol>
        <li><strong>The Marathon Task:</strong> Giving AI agents hours-long tasks without decomposition. With current models, a 3-hour task has <1% success rate.</li>
        <li><strong>The Context Stuffing:</strong> Believing that larger context windows solve reliability. The half-life model shows failure rate is time-based, not context-based.</li>
        <li><strong>The Success Extrapolation:</strong> Assuming that 80% success on 10-minute tasks means 64% on 20-minute tasks. In reality, it's exponential decay to ~40%.</li>
        <li><strong>The Single Point of Failure:</strong> Running one agent for critical tasks. Use ensemble methods for important operations.</li>
    </ol>

    <h2>Part 5: Organizational Readiness Timeline</h2>

    <p>Based on our unified model, organizations should plan their AI adoption strategy around these reliability thresholds:</p>

    <div class="timeline-box">
        <h3>Investment Roadmap</h3>
        <div class="timeline-item">
            <span class="timeline-date">Now (2025):</span><br>
            <strong>Invest in:</strong> Code review, test generation, documentation, bug triage<br>
            <strong>ROI:</strong> 20-40% developer productivity gains<br>
            <strong>Requirements:</strong> Human oversight, task decomposition
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2026-2027:</span><br>
            <strong>Prepare for:</strong> Feature implementation, refactoring, multi-file changes<br>
            <strong>ROI:</strong> 2-3√ó developer velocity on routine tasks<br>
            <strong>Requirements:</strong> Robust testing infrastructure, rollback systems
        </div>
        <div class="timeline-item">
            <span class="timeline-date">2028-2030:</span><br>
            <strong>Plan for:</strong> Sprint automation, complex debugging, system design<br>
            <strong>ROI:</strong> 10√ó productivity on well-defined projects<br>
            <strong>Requirements:</strong> New development workflows, AI-first architecture
        </div>
    </div>

    <h3>The Competitive Advantage Window</h3>

    <p>The exponential growth creates narrow windows of competitive advantage. Organizations that adopt AI capabilities 6-12 months early in each wave gain significant advantages, but waiting too long means competitors achieve the same capabilities. The key is identifying when reliability crosses the threshold for your specific use cases.</p>

    <div class="insight-box">
        <h3>Strategic Planning Framework</h3>
        <p>For any critical business process:</p>
        <ol>
            <li>Measure the actual time skilled humans take to complete it</li>
            <li>Determine your required reliability threshold</li>
            <li>Use the model to predict when AI will achieve that threshold</li>
            <li>Begin preparation 12-18 months before the threshold date</li>
        </ol>
    </div>

    <h2>Part 6: Limitations and Open Questions</h2>

    <h3>Model Limitations</h3>

    <p>While our unified model provides valuable predictions, several limitations must be acknowledged:</p>

    <div class="methodology-box">
        <h3>Known Limitations</h3>
        <ul>
            <li><strong>Benchmark vs. Reality:</strong> Real-world tasks often have hidden complexity not captured in benchmarks</li>
            <li><strong>Unstructured Problems:</strong> Tasks without clear success criteria remain difficult to measure</li>
            <li><strong>Compounding Errors:</strong> The model assumes independent failure probability, but errors often cascade</li>
            <li><strong>Human Factors:</strong> Doesn't account for human-AI collaboration dynamics</li>
            <li><strong>Paradigm Shifts:</strong> Assumes continued exponential growth without fundamental breakthroughs</li>
        </ul>
    </div>

    <h3>Open Research Questions</h3>

    <p>Several critical questions remain unanswered and represent active areas of research:</p>

    <ol>
        <li><strong>Can we change the hazard rate itself?</strong> Current models have a constant failure rate per minute. Can architectural innovations create models with decreasing hazard rates (improving reliability over time)?</li>
        <li><strong>What happens at the scaling limit?</strong> Will the 7-month doubling continue, slow down, or hit a wall?</li>
        <li><strong>How do we measure creative tasks?</strong> The model works well for well-defined tasks but struggles with open-ended creative work.</li>
        <li><strong>Can memory systems break the half-life constraint?</strong> Could external memory or retrieval systems fundamentally change the failure dynamics?</li>
    </ol>

    <h2>Part 7: Future Implications</h2>

    <h3>The 2030 Inflection Point</h3>

    <p>Our model suggests 2030 represents a critical inflection point where month-long tasks become automatable. This isn't just quantitative improvement‚Äîit's a qualitative shift in what's possible. Month-long tasks include:</p>

    <ul>
        <li>Complete software modules from specification to deployment</li>
        <li>Comprehensive security audits and penetration testing</li>
        <li>Full research projects with literature review and experimentation</li>
        <li>End-to-end business process redesigns</li>
    </ul>

    <p>Organizations that haven't adapted their workflows by this point will face existential competitive pressure. The difference between companies leveraging month-long AI automation and those limited to day-long tasks will be similar to the current gap between digitized and paper-based businesses.</p>

    <h3>The Path to AGI?</h3>

    <p>Interestingly, the half-life model provides a quantitative framework for thinking about artificial general intelligence (AGI). Human professionals can maintain performance over years-long projects. If the 7-month doubling continues, AI would match this around 2035-2040. However, this assumes no fundamental breakthroughs in error recovery or memory systems.</p>

    <div class="eli5-box">
        <h3>What This Means for Society</h3>
        <p>The convergence of exponential growth with predictable reliability thresholds creates a unique moment in history. We can now predict, with reasonable confidence, when specific cognitive tasks will become automatable. This isn't science fiction‚Äîit's engineering planning with quantifiable error bounds. Organizations, educational institutions, and governments that understand these dynamics can prepare proactively rather than react defensively.</p>
    </div>

    <div class="conclusion-box">
        <h2>Conclusion</h2>
        <p>The synthesis of Ord's half-life framework with METR's growth analysis provides the first quantitative model for predicting AI reliability thresholds. Current AI agents fail at a constant rate per minute (half-life model), but this rate improves exponentially, doubling every 7 months.</p>

        <p>For practitioners today, the message is clear: design systems around 7-minute subtasks for 90% reliability. For strategic planners, the roadmap is equally clear: prepare now for the capabilities coming in 2-3 years, not the limitations of today.</p>

        <p>The exponential curves create both opportunity and urgency. The organizations that understand these dynamics‚Äîthat recognize we're not approaching a plateau but riding an exponential curve‚Äîwill define the next decade of technological progress.</p>

        <p><strong>The question isn't whether AI will become reliable enough for your use case. It's whether you'll be ready when it does.</strong></p>
    </div>

    <div class="source-box">
        <h3>Primary Sources</h3>
        <p>
            <a href="https://www.tobyord.com/writing/half-life" target="_blank">Toby Ord: "Is there a Half-Life for the Success Rates of AI Agents?"</a><br>
            <em>Analysis of AI agent failure patterns using survival analysis and constant hazard rate models.</em>
        </p>
        <p>
            <a href="https://arxiv.org/html/2503.14499v2" target="_blank">METR: "Measuring AI Ability to Complete Long Tasks"</a><br>
            <em>Comprehensive study of 13 frontier models showing exponential growth in task completion capabilities.</em>
        </p>
    </div>

    <div class="navigation">
        <a href="../index.html">‚Üê Home</a>
        <a href="../agent/index.html">Agent Reliability</a>
        <a href="../rag/index.html">RAG Patterns</a>
        <a href="../research-papers/index.html">Research Papers</a>
        <a href="https://join.maxpool.dev" target="_blank">Join Community ‚Üí</a>
    </div>
</body>
</html>